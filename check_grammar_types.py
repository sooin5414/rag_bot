"""
ChromaDBì— ì €ì¥ëœ Grammar Type ìƒì„¸ í™•ì¸
"""
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma

embeddings = HuggingFaceEmbeddings(model_name="intfloat/multilingual-e5-large")
vectorstore = Chroma(
    persist_directory="./chroma_db",
    embedding_function=embeddings
)

collection = vectorstore._collection
all_results = collection.get(include=["metadatas", "documents"])

# Grammar Typeë³„ë¡œ ìƒ˜í”Œ ì¶œë ¥
grammar_samples = {}
for meta, doc in zip(all_results['metadatas'], all_results['documents']):
    grammar = meta.get('grammar_type', 'unknown')
    topic = meta.get('topic', 'unknown')

    if grammar not in grammar_samples:
        grammar_samples[grammar] = []

    if len(grammar_samples[grammar]) < 3:  # ê° íƒ€ì…ë‹¹ 3ê°œ ìƒ˜í”Œë§Œ
        grammar_samples[grammar].append({
            'topic': topic,
            'role': meta.get('role', 'unknown'),
            'summary': meta.get('summary', '')[:50],
            'content': doc[:80]
        })

print("ğŸ“š Grammar Typeë³„ ìƒ˜í”Œ\n")
for grammar_type, samples in sorted(grammar_samples.items()):
    count = sum(1 for m in all_results['metadatas'] if m.get('grammar_type') == grammar_type)
    print(f"ğŸ”¹ {grammar_type} ({count}ê°œ)")
    for i, sample in enumerate(samples, 1):
        print(f"  {i}. Topic: {sample['topic']}")
        print(f"     Role: {sample['role']}")
        print(f"     Summary: {sample['summary']}")
        print(f"     Content: {sample['content']}...")
        print()
