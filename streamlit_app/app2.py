"""
ì˜ì–´ í•™ìŠµ ë„ìš°ë¯¸ v2 - í•˜ì´ë¸Œë¦¬ë“œ
- Knowledge Graph (26ê°œ) + Smart Search (113ê°œ ì „ì²´)
- KGì— ì—†ëŠ” í† í”½ë„ Smart Searchë¡œ ì»¤ë²„
"""

import streamlit as st
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain_openai import ChatOpenAI
from openai import OpenAI
from dotenv import load_dotenv
from rapidfuzz import process, fuzz
import unicodedata
import json
import os

load_dotenv()

st.set_page_config(page_title="ì˜ì–´ í•™ìŠµ ë„ìš°ë¯¸ v2", page_icon="ğŸ“š", layout="wide")

# ============================================================
# ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
# ============================================================

@st.cache_resource
def load_vectorstore():
    embeddings = HuggingFaceEmbeddings(model_name="intfloat/multilingual-e5-large")
    vectorstore = Chroma(
        persist_directory="/data/edutem/sooine/rag_bot/chroma_db",
        embedding_function=embeddings,
 
    )
    return vectorstore

vectorstore = load_vectorstore()
client = OpenAI()
llm = ChatOpenAI(model="gpt-4o", temperature=0)

# Knowledge Graph ë¡œë“œ
@st.cache_resource
def load_knowledge_graph(_mtime):
    with open('/data/edutem/sooine/rag_bot/knowledge_graph.json', 'r', encoding='utf-8') as f:
        return json.load(f)

kg_path = '/data/edutem/sooine/rag_bot/knowledge_graph.json'
kg_mtime = os.path.getmtime(kg_path)
knowledge_graph = load_knowledge_graph(kg_mtime)

# ============================================================
# Knowledge Graph ê²€ìƒ‰ í•¨ìˆ˜
# ============================================================

def normalize(s):
    return unicodedata.normalize("NFC", s.lower().replace(" ", ""))

def fuzzy_match_topic(query, topic_list):
    q = normalize(query)
    candidates = [normalize(t) for t in topic_list]
    match_result, score, idx = process.extractOne(q, candidates, scorer=fuzz.ratio)
    if score > 70:
        return topic_list[idx]
    return None

def search_in_knowledge_graph(query):
    """ì§€ì‹ ê·¸ë˜í”„ì—ì„œ ê²€ìƒ‰"""
    query_lower = query.lower().strip()
    topic_list = list(knowledge_graph.keys())

    # 1ë‹¨ê³„: ì •í™•í•œ ì¼ì¹˜
    for main_topic in topic_list:
        if main_topic.lower() == query_lower:
            return {"type": "main_topic", "main_topic": main_topic, "data": knowledge_graph[main_topic]}

    # 2ë‹¨ê³„: ë¶€ë¶„ ì¼ì¹˜
    for main_topic in topic_list:
        if query_lower in main_topic.lower() or main_topic.lower() in query_lower:
            return {"type": "main_topic", "main_topic": main_topic, "data": knowledge_graph[main_topic]}

    # 3ë‹¨ê³„: Fuzzy match
    best = fuzzy_match_topic(query, topic_list)
    if best:
        return {"type": "main_topic", "main_topic": best, "data": knowledge_graph[best]}

    return None

# ============================================================
# Smart Search í•¨ìˆ˜
# ============================================================

def rewrite_query(query):
    """ì˜¤íƒ€ êµì • + ë¬¸ë²• í† í”½ ì¶”ì¶œ"""
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{
            "role": "user",
            "content": f"""ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ì˜ì–´ ë¬¸ë²• í† í”½ì„ ì¶”ì¶œí•˜ì„¸ìš”.

ì‚¬ìš©ì ì§ˆë¬¸: {query}

ê·œì¹™:
- í•µì‹¬ ë¬¸ë²• ìš©ì–´ë§Œ ì¶”ì¶œ
- ì˜¤íƒ€ êµì • (ë¹„ë™ì‚¬ â†’ beë™ì‚¬, ë¨¸ì•¼ â†’ ë­ì•¼)
- ì§ˆë¬¸ í˜•ì‹ ì œê±°
- ì˜ˆ: "ë¹„ë™ì‚¬ê°€ ë¨¸ì•¼?" â†’ "beë™ì‚¬"
- ì˜ˆ: "have pp ì–´ë–»ê²Œ ì¨?" â†’ "í˜„ì¬ì™„ë£Œ"

ì¶œë ¥: í† í”½ë§Œ (ì„¤ëª… ì—†ì´)"""
        }],
        max_tokens=50,
        temperature=0
    )
    return response.choices[0].message.content.strip()


def smart_search(query, k=5, threshold=0.35, rewritten=None):
    """Rewrite + ê²€ìƒ‰ + LLM íŒë‹¨"""
    
    # 1. Rewrite (ì˜¤íƒ€ êµì •)
    if rewritten is None:
        rewritten = rewrite_query(query)
    
    # 2. ê²€ìƒ‰
    results = vectorstore.similarity_search_with_score(rewritten, k=k)
    
    if not results:
        return {
            "found": False,
            "rewritten": rewritten,
            "keyword": rewritten,
            "message": "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.",
            "results": []
        }
    
    # ë¡œê·¸
    print(f"\n{'='*60}")
    print(f"Query: {query} â†’ Rewritten: {rewritten}")
    for i, (doc, score) in enumerate(results):
        print(f"  {i}. [{score:.3f}] {doc.metadata.get('topic')}")
    
    # 3. ì»¨í…ìŠ¤íŠ¸ ìƒì„± (í† í”½, ì ìˆ˜, ì‹œê°„, ë‚´ìš© í¬í•¨)
    context = "\n".join([
        f"{i}. {doc.metadata.get('topic')} (score: {score:.3f}, start: {doc.metadata.get('start_time', 0):.1f}ì´ˆ): {doc.page_content[:100]}..."
        for i, (doc, score) in enumerate(results)
    ])

    # 4. LLM íŒë‹¨
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{
            "role": "user",
            "content": f"""ì˜ì–´ ë¬¸ë²• ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì„¸ìš”.

ì§ˆë¬¸: {query}
ê²€ìƒ‰ì–´: {rewritten}

ê²€ìƒ‰ ê²°ê³¼:
{context}

JSON ì‘ë‹µ:
{{
    "found": true/false (ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ê²°ê³¼ê°€ ìˆëŠ”ì§€),
    "best_index": ê°€ì¥ ì í•©í•œ ê²°ê³¼ ë²ˆí˜¸ (0~{k-1}),
    "best_topic": "ê°€ì¥ ì í•©í•œ í† í”½",
    "keyword": "í•µì‹¬ ë¬¸ë²• í‚¤ì›Œë“œ",
    "message": "ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ë©”ì‹œì§€ (í•œêµ­ì–´)"
}}

ì„ íƒ ê·œì¹™ (ìˆœì„œëŒ€ë¡œ ì ìš©):
1. **í† í”½ ì •í™•ë„ ìš°ì„ **: ì§ˆë¬¸ì´ "~ê°€ ë­ì•¼?" ê°™ì€ ê¸°ë³¸ ê°œë… ì§ˆë¬¸ì´ë©´, ê²€ìƒ‰ì–´ì™€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” í† í”½ì„ ì„ íƒ
   - ì˜ˆ: "ìˆ˜ë™íƒœê°€ ë­ì•¼?" â†’ "ìˆ˜ë™íƒœ" (O), "ìˆ˜ë™íƒœì˜ ë‹¤ì–‘í•œ ì‹œì œ" (X - ì„¸ë¶€ ì£¼ì œì„)
   - ì˜ˆ: "beë™ì‚¬ê°€ ë­ì•¼?" â†’ "beë™ì‚¬" (O), "beë™ì‚¬ì˜ ë¶€ì •ë¬¸" (X)
2. **ì ìˆ˜ ê³ ë ¤**: í† í”½ì´ ê°™ë‹¤ë©´ scoreê°€ ë‚®ì€ ê²ƒ ì„ íƒ (scoreê°€ ë‚®ì„ìˆ˜ë¡ ê´€ë ¨ì„± ë†’ìŒ)
3. **ì‹œê°„ ê³ ë ¤**: í† í”½ê³¼ ì ìˆ˜ê°€ ë¹„ìŠ·í•˜ë©´ start ì‹œê°„ì´ ë¹ ë¥¸ ê²ƒ ì„ íƒ
4. score > {threshold}ì´ë©´ ê´€ë ¨ì„± ë‚®ìŒ (found: false)"""
        }],
        response_format={"type": "json_object"},
        max_tokens=200,
        temperature=0
    )
    
    judgment = json.loads(response.choices[0].message.content)
    
    # 5. ê²°ê³¼ êµ¬ì„±
    best_idx = min(judgment.get("best_index", 0), len(results) - 1)
    best_doc, best_score = results[best_idx]

    # Score threshold ì²´í¬ (ë‹¨, LLMì´ ì •í™•í•œ í† í”½ ë§¤ì¹­ì„ ì°¾ì•˜ë‹¤ë©´ ì•½ê°„ì˜ ì—¬ìœ  í—ˆìš©)
    best_topic = judgment.get("best_topic", "")
    if best_score > threshold:
        # LLMì´ ì°¾ì€ í† í”½ì´ rewrittenê³¼ ì •í™•íˆ ì¼ì¹˜í•˜ë©´ thresholdë¥¼ ì•½ê°„ ì™„í™” (0.05 ì—¬ìœ )
        if best_topic != rewritten or best_score > threshold + 0.05:
            judgment["found"] = False
    
    print(f"  â†’ found: {judgment['found']}, best: {judgment.get('best_topic')}")
    
    return {
        **judgment,
        "rewritten": rewritten,
        "score": best_score,
        "doc": best_doc,
        "video_url": best_doc.metadata.get('video_url'),
        "start_time": best_doc.metadata.get('start_time'),
        "end_time": best_doc.metadata.get('end_time'),
        "results": results
    }


def get_video_embed(url, start, end):
    """YouTube ì„ë² ë“œ URL ìƒì„±"""
    if not url:
        return None
    if "watch?v=" in url:
        video_id = url.split("watch?v=")[-1].split("&")[0]
    elif "youtu.be/" in url:
        video_id = url.split("youtu.be/")[-1].split("?")[0]
    else:
        return None
    return f"https://www.youtube.com/embed/{video_id}?start={int(start)}&end={int(end)}"


# ============================================================
# UI
# ============================================================

st.title("ğŸ“š ì˜ì–´ í•™ìŠµ ë„ìš°ë¯¸ v2")
st.markdown("í•˜ì´ë¸Œë¦¬ë“œ: Knowledge Graph + Smart Search")

# ì„¸ì…˜ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")

    # ê²€ìƒ‰ ëª¨ë“œ ì„ íƒ
    search_mode = st.radio(
        "ê²€ìƒ‰ ëª¨ë“œ",
        ["ğŸ” í•˜ì´ë¸Œë¦¬ë“œ (KG ìš°ì„ )", "âš¡ Smart Searchë§Œ"],
        index=0,
        help="í•˜ì´ë¸Œë¦¬ë“œ: KGì—ì„œ ë¨¼ì € ì°¾ê³  ì—†ìœ¼ë©´ Smart Search\nSmart Searchë§Œ: ì „ì²´ 113ê°œ í† í”½ ì§ì ‘ ê²€ìƒ‰"
    )

    st.divider()

    threshold = st.slider(
        "ê²€ìƒ‰ ë¯¼ê°ë„ (threshold)",
        min_value=0.20,
        max_value=0.50,
        value=0.35,
        step=0.05,
        help="ë‚®ì„ìˆ˜ë¡ ì—„ê²©í•˜ê²Œ 'ì—†ìŒ' íŒì •"
    )

    st.divider()

    # Knowledge Graph ì£¼ì œ í‘œì‹œ
    #st.markdown("### ğŸ“š KG ì£¼ì œ")
    #st.caption(f"{len(knowledge_graph)}ê°œ")
    #with st.expander("ì£¼ì œ ëª©ë¡"):
    #    for topic in list(knowledge_graph.keys()):
    #        st.markdown(f"- {topic}")

    st.divider()

    if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state["messages"] = []
        st.rerun()

    st.divider()
    st.markdown("### ğŸ“Š ì‹œìŠ¤í…œ")
    st.markdown("- ChromaDB: 149ê°œ í† í”½, 384 ë¬¸ì„œ")
    st.markdown("- KG: 26ê°œ ì£¼ì œ")
    st.markdown("- LLM: GPT-4o")

# ì‚¬ìš©ì ì…ë ¥
user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")

if user_input:
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        with st.spinner("ê²€ìƒ‰ ì¤‘..."):

            if "í•˜ì´ë¸Œë¦¬ë“œ" in search_mode:
                # ========== í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ: KG ìš°ì„  â†’ ì—†ìœ¼ë©´ Smart Search ==========
                rewritten = rewrite_query(user_input) 
                kg_result = search_in_knowledge_graph(rewritten)

                if kg_result:
                    # KGì—ì„œ ì°¾ìŒ
                    st.caption("ğŸ” Knowledge Graphì—ì„œ ì°¾ìŒ")
                    main_topic = kg_result['main_topic']

                    # LLM ì„¤ëª…
                    st.markdown(f"## ğŸ’¡ {main_topic}")
                    with st.spinner("ì„¤ëª… ìƒì„± ì¤‘..."):
                        explain_prompt = f"'{main_topic}'ì´ ë¬´ì—‡ì¸ì§€ í•µì‹¬ë§Œ ê°„ë‹¨íˆ 2-3ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
                        explanation = llm.invoke(explain_prompt).content.strip()
                    st.write(explanation)

                    st.markdown("---")
                    st.success(f"âœ… '{main_topic}' ê°•ì˜ê°€ ìˆì–´ìš”!")

                    # Smart Searchë¡œ ìµœì  ì˜ìƒ êµ¬ê°„ ì°¾ê¸°
                    search_result = smart_search(main_topic, threshold=threshold, rewritten=main_topic)
                    if search_result["found"]:
                        st.markdown("### ğŸ“º ê°•ì˜ ì˜ìƒ")
                        video_url = search_result.get("video_url")
                        start = int(float(search_result.get("start_time", 0)))
                        end = int(float(search_result.get("end_time", 0)))

                        embed_url = get_video_embed(video_url, start, end)
                        if embed_url:
                            st.components.v1.iframe(embed_url, width=800, height=450)
                            st.caption(f"â±ï¸ {start}ì´ˆ ~ {end}ì´ˆ | Score: {search_result['score']:.3f}")

                        # ê´€ë ¨ ì£¼ì œ
                        st.markdown("---")
                        st.markdown("### ğŸ”— ê´€ë ¨ ì£¼ì œ")
                        shown = {search_result.get("best_topic", "")}
                        for doc, doc_score in search_result.get("results", [])[1:]:
                            rel_topic = doc.metadata.get("topic", "")
                            if rel_topic and rel_topic not in shown and doc_score <= threshold:
                                shown.add(rel_topic)
                                with st.expander(f"âœ… {rel_topic} (score: {doc_score:.3f})"):
                                    rel_url = doc.metadata.get('video_url', '')
                                    rel_start = int(float(doc.metadata.get('start_time', 0)))
                                    rel_end = int(float(doc.metadata.get('end_time', 0)))
                                    rel_embed = get_video_embed(rel_url, rel_start, rel_end)
                                    if rel_embed:
                                        st.components.v1.iframe(rel_embed, width=700, height=400)

                else:
                    # KGì— ì—†ìŒ â†’ Smart Searchë¡œ ì „í™˜
                    st.caption("âš¡ KGì— ì—†ìŒ â†’ Smart Search ì‚¬ìš©")
                    result = smart_search(user_input, threshold=threshold, rewritten=rewritten)

                    keyword = result.get("keyword", user_input)
                    rewritten = result.get("rewritten", "")
                    score = result.get("score", 1.0)

                    if result["found"]:
                        # ì°¾ì•˜ì„ ë•Œ
                        topic = result.get("best_topic", "")

                        st.markdown(f"## ğŸ’¡ {keyword}")
                        st.caption(f"ğŸ” {user_input} â†’ {rewritten} â†’ {topic} (score: {score:.3f})")

                        st.success(f"âœ… '{topic}' ê°•ì˜ê°€ ìˆì–´ìš”!")

                        # ì˜ìƒ
                        video_url = result.get("video_url")
                        start = int(float(result.get("start_time", 0)))
                        end = int(float(result.get("end_time", 0)))

                        if video_url:
                            st.markdown("### ğŸ“º ê°•ì˜ ì˜ìƒ")
                            embed_url = get_video_embed(video_url, start, end)
                            if embed_url:
                                st.components.v1.iframe(embed_url, width=800, height=450)
                                st.caption(f"â±ï¸ {start}ì´ˆ ~ {end}ì´ˆ")

                        # ê´€ë ¨ ì£¼ì œ
                        st.markdown("---")
                        st.markdown("### ğŸ”— ê´€ë ¨ ì£¼ì œ")

                        shown = {topic}
                        for doc, doc_score in result["results"][1:]:
                            rel_topic = doc.metadata.get("topic", "")
                            if rel_topic and rel_topic not in shown and doc_score <= threshold:
                                shown.add(rel_topic)
                                with st.expander(f"âœ… {rel_topic} (score: {doc_score:.3f})"):
                                    rel_url = doc.metadata.get('video_url', '')
                                    rel_start = int(float(doc.metadata.get('start_time', 0)))
                                    rel_end = int(float(doc.metadata.get('end_time', 0)))
                                    rel_embed = get_video_embed(rel_url, rel_start, rel_end)
                                    if rel_embed:
                                        st.components.v1.iframe(rel_embed, width=700, height=400)

                    else:
                        # ëª» ì°¾ì•˜ì„ ë•Œ
                        st.markdown(f"## ğŸ’¡ {keyword}")
                        st.caption(f"ğŸ” {user_input} â†’ {rewritten} (score: {score:.3f})")

                        st.warning(f"ğŸ“­ '{keyword}'ì„(ë¥¼) ì§ì ‘ ë‹¤ë£¨ëŠ” ê°•ì˜ê°€ ì—†ì–´ìš”.")

                        # ê°€ì¥ ê°€ê¹Œìš´ í† í”½ ì œì•ˆ
                        if result.get("results"):
                            closest = result["results"][0][0].metadata.get("topic", "")
                            if closest:
                                st.info(f"ğŸ’¡ ê°€ì¥ ê°€ê¹Œìš´ í† í”½: **{closest}**")

            else:
                # ========== Smart Searchë§Œ ì‚¬ìš© ==========
                result = smart_search(user_input, threshold=threshold)

                keyword = result.get("keyword", user_input)
                rewritten = result.get("rewritten", "")
                score = result.get("score", 1.0)

                if result["found"]:
                    topic = result.get("best_topic", "")

                    st.markdown(f"## ğŸ’¡ {keyword}")
                    st.caption(f"ğŸ” {user_input} â†’ {rewritten} â†’ {topic} (score: {score:.3f})")

                    st.success(f"âœ… '{topic}' ê°•ì˜ê°€ ìˆì–´ìš”!")

                    video_url = result.get("video_url")
                    start = int(float(result.get("start_time", 0)))
                    end = int(float(result.get("end_time", 0)))

                    if video_url:
                        st.markdown("### ğŸ“º ê°•ì˜ ì˜ìƒ")
                        embed_url = get_video_embed(video_url, start, end)
                        if embed_url:
                            st.components.v1.iframe(embed_url, width=800, height=450)
                            st.caption(f"â±ï¸ {start}ì´ˆ ~ {end}ì´ˆ")

                    st.markdown("---")
                    st.markdown("### ğŸ”— ê´€ë ¨ ì£¼ì œ")

                    shown = {topic}
                    for doc, doc_score in result["results"][1:]:
                        rel_topic = doc.metadata.get("topic", "")
                        if rel_topic and rel_topic not in shown and doc_score <= threshold:
                            shown.add(rel_topic)
                            with st.expander(f"âœ… {rel_topic} (score: {doc_score:.3f})"):
                                rel_url = doc.metadata.get('video_url', '')
                                rel_start = int(float(doc.metadata.get('start_time', 0)))
                                rel_end = int(float(doc.metadata.get('end_time', 0)))
                                rel_embed = get_video_embed(rel_url, rel_start, rel_end)
                                if rel_embed:
                                    st.components.v1.iframe(rel_embed, width=700, height=400)
                else:
                    st.markdown(f"## ğŸ’¡ {keyword}")
                    st.caption(f"ğŸ” {user_input} â†’ {rewritten} (score: {score:.3f})")

                    st.warning(f"ğŸ“­ '{keyword}'ì„(ë¥¼) ì§ì ‘ ë‹¤ë£¨ëŠ” ê°•ì˜ê°€ ì—†ì–´ìš”.")

                    if result.get("results"):
                        closest = result["results"][0][0].metadata.get("topic", "")
                        if closest:
                            st.info(f"ğŸ’¡ ê°€ì¥ ê°€ê¹Œìš´ í† í”½: **{closest}**")

