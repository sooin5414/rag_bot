#!/data/edutem/.cache/pypoetry/virtualenvs/rag-bot-vbdTYmCJ-py3.12/bin/python
"""
ì¹´ë“œ í˜•ì‹ UI + ë‹¤ì¤‘ ë‹µë³€ ì§€ì›
"""
import streamlit as st
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from sentence_transformers import CrossEncoder
from dotenv import load_dotenv
import torch
from openai import OpenAI
import json
import re

load_dotenv()
client = OpenAI()

# =====================
# Config
# =====================
CHROMA_DIR = "/data/edutem/sooine/rag_bot/chroma_db_with_role"
EMBED_MODEL = "intfloat/multilingual-e5-large"
RERANK_MODEL = "BAAI/bge-reranker-v2-m3"

# =====================
# Load resources
# =====================
@st.cache_resource
def load_vectorstore():
    embeddings = HuggingFaceEmbeddings(
        model_name=EMBED_MODEL,
        encode_kwargs={"normalize_embeddings": True}
    )
    return Chroma(
        persist_directory=CHROMA_DIR,
        embedding_function=embeddings,
    )

@st.cache_resource
def load_reranker():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    return CrossEncoder(RERANK_MODEL, device=device, max_length=512)

vectorstore = load_vectorstore()
reranker = load_reranker()

# =====================
# Core Functions
# =====================
def analyze_query_intent(query: str) -> dict:
    """ì§ˆë¬¸ ì˜ë„ íŒŒì•… (LLM)"""
    prompt = f"""
    ì•„ë˜ ì§ˆë¬¸ì„ ë¶„ì„í•´ì„œ JSONìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.

    ì§ˆë¬¸: {query}

    ë°˜í™˜ í˜•ì‹:
    {{
        "grammar_type": "ì‹œì œ | beë™ì‚¬ | ì¡°ë™ì‚¬ | ë¬¸ì¥êµ¬ì¡° | ì „ì¹˜ì‚¬ | ë™ì‚¬ | ê¸°íƒ€",
        "specificity": "broad | specific",
        "desired_role": "definition | usage | comparison | practice"
    }}

    íŒë‹¨ ê¸°ì¤€:
    - broad: "í˜„ì¬ì‹œì œê°€ ë­ì•¼?", "beë™ì‚¬ ì•Œë ¤ì¤˜" ê°™ì€ í¬ê´„ì  ì§ˆë¬¸
    - specific: "í˜„ì¬ì™„ë£Œ ì˜ˆë¬¸ ë³´ì—¬ì¤˜", "canì˜ ìš©ë²•" ê°™ì€ êµ¬ì²´ì  ì§ˆë¬¸
    - desired_role: ì§ˆë¬¸ì—ì„œ ì›í•˜ëŠ” ë‚´ìš© (ë­ì•¼?â†’definition, ì–´ë–»ê²Œ?â†’usage, ì˜ˆë¬¸â†’practice)
    """

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"},
        temperature=0
    )

    return json.loads(response.choices[0].message.content)


def smart_search(query: str) -> dict:
    """ê°œì„ ëœ ê²€ìƒ‰: ì‹ ë¢°ë„ + ì˜ë„ ê¸°ë°˜"""
    # Step 1: ì˜ë„ íŒŒì•…
    intent = analyze_query_intent(query)

    # Step 2: Vector Search + Rerank
    docs = vectorstore.similarity_search(query, k=20)
    pairs = [[query, doc.page_content] for doc in docs]
    scores = reranker.predict(pairs)

    ranked_indices = scores.argsort()[::-1]
    ranked_docs = [docs[i] for i in ranked_indices]
    ranked_scores = [scores[i] for i in ranked_indices]

    top_score = ranked_scores[0]

    # Step 3: ì‹ ë¢°ë„ + ì˜ë„ ì¡°í•© íŒë‹¨
    if top_score > 0.7:
        # ê³ ì‹ ë¢°ë„ â†’ ë‹¨ì¼ ë‹µë³€
        return {
            "mode": "single",
            "doc": ranked_docs[0],
            "score": float(top_score),
            "confidence": "high",
            "intent": intent
        }

    elif intent['specificity'] == 'broad' and top_score < 0.7:
        # í¬ê´„ì  ì§ˆë¬¸ + ì €ì‹ ë¢°ë„ â†’ ì—¬ëŸ¬ ê°œ ë³´ì—¬ì£¼ê¸°
        filtered = [
            (d, s) for d, s in zip(ranked_docs[:10], ranked_scores[:10])
            if d.metadata.get('grammar_type') == intent['grammar_type']
        ]

        # Role ìš°ì„ ìˆœìœ„ ì •ë ¬
        role_priority = {'definition': 3, 'usage': 2, 'comparison': 1, 'practice': 1}
        filtered.sort(
            key=lambda x: (
                role_priority.get(x[0].metadata.get('role'), 0),
                x[1]  # score
            ),
            reverse=True
        )

        top_docs = [d for d, s in filtered[:3]]
        top_scores = [s for d, s in filtered[:3]]

        return {
            "mode": "multi",
            "docs": top_docs,
            "scores": [float(s) for s in top_scores],
            "message": f"'{intent['grammar_type']}' ê´€ë ¨ ì£¼ì œë“¤ì…ë‹ˆë‹¤:",
            "confidence": "medium",
            "intent": intent
        }

    else:
        # êµ¬ì²´ì  ì§ˆë¬¸ + ì¤‘ì‹ ë¢°ë„ â†’ Top 3 ì„ íƒì§€
        return {
            "mode": "choice",
            "docs": ranked_docs[:3],
            "scores": [float(s) for s in ranked_scores[:3]],
            "message": "í˜¹ì‹œ ì´ ì¤‘ í•˜ë‚˜ë¥¼ ì°¾ìœ¼ì‹œë‚˜ìš”?",
            "confidence": "medium",
            "intent": intent
        }


def youtube_embed(video_url: str, start: float, end: float) -> str:
    """YouTube embed URL ìƒì„±"""
    match = re.search(r'(?:v=|/)([a-zA-Z0-9_-]{11})', video_url)
    if not match:
        return None
    vid = match.group(1)
    return f"https://www.youtube.com/embed/{vid}?start={int(start)}&end={int(end)}"


# =====================
# UI Styling
# =====================
st.set_page_config(page_title="ì˜ì–´ í•™ìŠµ ë„ìš°ë¯¸")

# Custom CSS for chat-like UI
st.markdown("""
<style>
    .user-message {
        background-color: #E3F2FD;
        padding: 15px 20px;
        border-radius: 15px;
        margin: 10px 0;
        margin-left: 20%;
        text-align: right;
    }

    .bot-message {
        background-color: #F5F5F5;
        padding: 15px 20px;
        border-radius: 15px;
        margin: 10px 0;
        margin-right: 20%;
    }

    .video-card {
        background-color: white;
        border: 1px solid #E0E0E0;
        border-radius: 10px;
        padding: 15px;
        margin: 10px 0;
    }

    .topic-badge {
        display: inline-block;
        background-color: #2196F3;
        color: white;
        padding: 5px 12px;
        border-radius: 15px;
        font-size: 0.85em;
        margin-right: 10px;
    }

    .role-badge {
        display: inline-block;
        background-color: #4CAF50;
        color: white;
        padding: 5px 12px;
        border-radius: 15px;
        font-size: 0.85em;
    }

    /* ì…ë ¥ì°½ ìŠ¤íƒ€ì¼ë§ */
    [data-testid="stChatInput"] {
        max-width: 800px;
        margin: 0 auto;
    }

    /* ì…ë ¥ì°½ì„ í¬í•¨í•˜ëŠ” ì»¨í…Œì´ë„ˆ */
    [data-testid="stBottom"] {
        background-color: white;
        border-top: 1px solid #e0e0e0;
        padding: 1rem 0;
    }

    /* ë©”ì‹œì§€ ì˜ì—­ì— í•˜ë‹¨ ì—¬ë°± ì¶”ê°€ */
    .main .block-container {
        padding-bottom: 100px;
    }
</style>
""", unsafe_allow_html=True)

# =====================
# Main UI
# =====================
st.title("ğŸ“ ì˜ì–´ í•™ìŠµ ë„ìš°ë¯¸")

# Initialize session state
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display chat history
for msg in st.session_state.messages:
    if msg["role"] == "user":
        st.markdown(f'<div class="user-message">ğŸ‘¤ {msg["content"]}</div>', unsafe_allow_html=True)
    else:
        st.markdown(f'<div class="bot-message">ğŸ¤– {msg["content"]}</div>', unsafe_allow_html=True)

        # Display videos if present
        if "videos" in msg:
            for video in msg["videos"]:
                with st.expander(f"ğŸ“º {video['topic']}", expanded=True):
                    col1, col2 = st.columns([3, 2])

                    with col1:
                        embed_url = video.get('embed_url')
                        if embed_url:
                            st.components.v1.iframe(embed_url, width=500, height=300)

                    with col2:
                        st.markdown(f"**{video['topic']}**")
                        st.caption(f"ğŸ·ï¸ {video['grammar_type']} | {video['role']}")
                        st.write(video['content'])
                        st.caption(f"â±ï¸ {video['start']:.1f}s ~ {video['end']:.1f}s")

# Input
query = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: í˜„ì¬ì‹œì œê°€ ë­ì•¼?)")

if query:
    # Add user message
    st.session_state.messages.append({"role": "user", "content": query})

    # Search
    with st.spinner("ê²€ìƒ‰ ì¤‘..."):
        result = smart_search(query)

    # Generate response based on mode
    if result["mode"] == "single":
        doc = result["doc"]
        meta = doc.metadata

        response_text = f"**{meta.get('topic')}**\n\n{doc.page_content}"

        video_info = [{
            "topic": meta.get('topic'),
            "grammar_type": meta.get('grammar_type'),
            "role": meta.get('role'),
            "content": doc.page_content,
            "start": meta.get('start_time', 0),
            "end": meta.get('end_time', 0),
            "embed_url": youtube_embed(meta.get('video_url', ''), meta.get('start_time', 0), meta.get('end_time', 0))
        }]

        st.session_state.messages.append({
            "role": "assistant",
            "content": response_text,
            "videos": video_info
        })

    elif result["mode"] in ["multi", "choice"]:
        response_text = result["message"]

        video_info = []
        for doc in result["docs"]:
            meta = doc.metadata
            video_info.append({
                "topic": meta.get('topic'),
                "grammar_type": meta.get('grammar_type'),
                "role": meta.get('role'),
                "content": doc.page_content,
                "start": meta.get('start_time', 0),
                "end": meta.get('end_time', 0),
                "embed_url": youtube_embed(meta.get('video_url', ''), meta.get('start_time', 0), meta.get('end_time', 0))
            })

        st.session_state.messages.append({
            "role": "assistant",
            "content": response_text,
            "videos": video_info
        })

    st.rerun()
