import streamlit as st
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from sentence_transformers import CrossEncoder
from dotenv import load_dotenv
import torch
from openai import OpenAI
import json

load_dotenv()
client = OpenAI()


# =====================
# Config
# =====================
CHROMA_DIR = "/data/edutem/sooine/rag_bot/chroma_db_with_role"
EMBED_MODEL = "intfloat/multilingual-e5-large"
RERANK_MODEL = "BAAI/bge-reranker-v2-m3"

# =====================
# Load resources
# =====================
@st.cache_resource
def load_vectorstore():
    embeddings = HuggingFaceEmbeddings(
        model_name=EMBED_MODEL,
        encode_kwargs={"normalize_embeddings": True}
    )
    return Chroma(
        persist_directory=CHROMA_DIR,
        embedding_function=embeddings,
    )

@st.cache_resource
def load_reranker():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    return CrossEncoder(RERANK_MODEL, device=device, max_length=512)

@st.cache_resource
def load_all_topics(_vectorstore):
    metas = _vectorstore._collection.get(include=["metadatas"])["metadatas"]
    return list({m["topic"] for m in metas if m and "topic" in m})

vectorstore = load_vectorstore()
reranker = load_reranker()

ALL_TOPICS = load_all_topics(vectorstore)

def extract_asked_topic(query: str, all_topics: list[str]) -> str | None:
    q = query.replace(" ", "")
    for t in all_topics:
        if t.replace(" ", "") in q:
            return t
    return None

def rewrite_query_structured(query: str, all_topics: list[str]) -> dict:
    topics = all_topics[:180]

    prompt = f"""
            ë„ˆëŠ” ì˜ì–´ ë¬¸ë²• êµìœ¡ ì‹œìŠ¤í…œì˜ Query Routerë‹¤.

            ì‚¬ìš©ì ì§ˆë¬¸ì„ ë³´ê³ ,
            1.  ê°€ì¥ ì ì ˆí•œ ì˜ì–´ ë¬¸ë²• 'í† í”½ 1ê°œ'
            2. ì‚¬ìš©ìì˜ í•µì‹¬ ì˜ë„(role) 1ê°œë§Œ
            ì„ ì¶”ì¶œí•˜ë¼.

            role ì •ì˜:
            - definition : ê°œë…/ì˜ë¯¸ê°€ ë¬´ì—‡ì¸ì§€
            - usage      : ì–¸ì œ/ì–´ë–»ê²Œ ì“°ëŠ”ì§€
            - comparison : ë‹¤ë¥¸ ë¬¸ë²•ê³¼ì˜ ì°¨ì´
            - practice   : ì˜ˆë¬¸/ì—°ìŠµ/ë¬¸ì œ

            ì¤‘ìš” ê·œì¹™:
            - roleì€ ë°˜ë“œì‹œ 1ê°œë§Œ ì„ íƒ
            - topicì´ ì •í™•íˆ ì—†ìœ¼ë©´, ê°€ì¥ ê°€ê¹Œìš´ ìƒìœ„ ê°œë…ì„ ì„ íƒ
            - êµ¬ì–´ì²´, ì˜¤íƒ€, ë¶™ì—¬ì“´ í‘œí˜„ì€ ì •ìƒí™”í•´ì„œ íŒë‹¨
            - í™•ì‹ ì´ ë‚®ìœ¼ë©´ confidenceë¥¼ ë‚®ê²Œ ì„¤ì •

            ì˜¤íƒ€ ì²˜ë¦¬ ì˜ˆì‹œ:
            - "íˆ¬ë¶€ì •ì‚¬" â†’ "toë¶€ì •ì‚¬"
            - "ë¹„ë™ì‚¬" â†’ "beë™ì‚¬"
            - "í˜„ì œì™„ë£Œ" â†’ "í˜„ì¬ì™„ë£Œ"
            - "ê³¼ê±°í˜•" â†’ "ê³¼ê±°"

            ì‚¬ìš©ì ì§ˆë¬¸:
            {query}

            í† í”½ í›„ë³´:
            {topics}

            ì¶œë ¥(JSON only):
            {{
            "topic": "ì„ íƒí•œ í† í”½ (ë°˜ë“œì‹œ 1ê°œ)",
            "role": "definition | usage | comparison | practice",
            "confidence": "high | medium | low"
            }}
"""

    res = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"},
        temperature=0,
        max_tokens=80
    )

    return json.loads(res.choices[0].message.content)

def has_definition(topic: str, docs) -> bool:
    for d in docs:
        if (
            d.metadata.get("topic") == topic and
            d.metadata.get("role") == "definition"
        ):
            return True
    return False

def decide_educational_response(query, routed, retrieved_docs):
    topic  = routed["topic"]
    intent = routed["intent"]

    # 1. ê°œë… ìì²´ê°€ ì—†ìŒ
    if topic not in ALL_TOPICS:
        return {
            "type": "concept_missing",
            "topic": topic
        }

    # 2. ì •ì˜ ì§ˆë¬¸ì¸ë° ì •ì˜ ê°•ì˜ ì—†ìŒ
    if intent == "definition" and not has_definition(topic, retrieved_docs):
        return {
            "type": "definition_missing",
            "topic": topic
        }

    # 3. ì •ìƒ â†’ ì˜ìƒ ì„ íƒ ê°€ëŠ¥
    return {
        "type": "video_ok",
        "topic": topic
    }

def build_definition_missing_message(topic: str, vectorstore):
    # ê°™ì€ grammar_typeì˜ ë‹¤ë¥¸ topic ìˆ˜ì§‘
    metas = vectorstore._collection.get(include=["metadatas"])["metadatas"]

    related = {}
    for m in metas:
        if not m:
            continue
        if m.get("grammar_type") == "ì‹œì œ" and m.get("topic") != topic:
            related[m["topic"]] = m.get("summary", "")

    lines = [f"- **{t}**: {s}" for t, s in related.items()]

    return f"""
âš ï¸ **{topic}** ìì²´ë¥¼ ì„¤ëª…í•˜ëŠ” ê°•ì˜ëŠ” ì•„ì§ ì—†ìŠµë‹ˆë‹¤.

ëŒ€ì‹ , í˜„ì¬ì™€ ê´€ë ¨ëœ ì‹œì œ ê°•ì˜ëŠ” ë‹¤ìŒì´ ìˆìŠµë‹ˆë‹¤:
{chr(10).join(lines)}

ğŸ‘‰ **{topic} (ìŠµê´€ / ì‚¬ì‹¤)** ì— ëŒ€í•œ ê°•ì˜ëŠ” ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤.
"""
def generate_concept_summary(query: str) -> str:
    prompt = f"""
ë„ˆëŠ” ì˜ì–´ ë¬¸ë²•ì„ ì„¤ëª…í•˜ëŠ” ì „ë¬¸ íŠœí„°ë‹¤.

ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´:
- ì§ˆë¬¸ì—ì„œ ë¬»ëŠ” ê°œë… ìì²´ë¥¼ ì„¤ëª…í•˜ë¼
- 2~3ë¬¸ì¥ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ì„¤ëª…í•˜ë¼
- ê°•ì˜, ì˜ìƒ, ìë£Œì˜ ì¡´ì¬ ì—¬ë¶€ëŠ” ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ˆë¼
- ì§ˆë¬¸ì´ ëª¨í˜¸í•˜ë©´, ê°€ì¥ ì¼ë°˜ì ì¸ ë¬¸ë²•ì  ì˜ë¯¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì„¤ëª…í•˜ë¼
- ë‹¤ë¥¸ ë¬¸ë²• ê°œë…ìœ¼ë¡œ ë°”ê¿”ì„œ ì„¤ëª…í•˜ì§€ ë§ˆë¼

ì‚¬ìš©ì ì§ˆë¬¸:
{query}

ì¶œë ¥:
- í•œêµ­ì–´ ë¬¸ì¥ë§Œ ì¶œë ¥
"""
    try:
        res = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            max_tokens=120,
        )
        return res.choices[0].message.content.strip()
    except Exception:
        return ""

# =====================
# Core logic
# =====================
def search_video(query: str, k: int = 12):
    # =========================
    # 0. Routing
    # =========================
    routed = rewrite_query_structured(query, ALL_TOPICS)

    asked_topic = extract_asked_topic(query, ALL_TOPICS)      # ì‚¬ìš©ìê°€ ì‹¤ì œë¡œ ë¬¼ì€ ê°œë…
    candidate_topic = routed.get("topic")                     # ê²€ìƒ‰ìš© í† í”½
    role = routed.get("role", "definition")                   # definition / usage / ...
    
    # =========================
    # ğŸ”´ í•µì‹¬ ê°€ë“œ: asked_topicì´ DBì— ì—†ìœ¼ë©´ ê²€ìƒ‰ ê¸ˆì§€
    # =========================
    if role == "definition" and asked_topic:
        if asked_topic not in ALL_TOPICS:
            return {
                "type": "definition_missing",
                "topic": asked_topic,
                "related_topics": [],
                "routed": routed,
            }
    
    
    route_conf = routed.get("confidence", "low")

    # =========================
    # 1. Vector search (candidate_topic ê¸°ì¤€)
    # =========================
    if isinstance(candidate_topic, str) and candidate_topic.strip():
        raw = vectorstore.similarity_search_with_score(
            query,
            k=k,
            filter={"topic": candidate_topic}
        )
    else:
        raw = vectorstore.similarity_search_with_score(query, k=k)

    if not raw:
        return None

    retrieved_docs = [doc for doc, _ in raw]

    # =========================
    # 2. Definition-missing íŒë‹¨ (asked_topic ê¸°ì¤€)
    # =========================
    if role == "definition" and asked_topic:
        if not has_definition(asked_topic, retrieved_docs):

            # ê°™ì€ grammar_typeì˜ ë‹¤ë¥¸ í† í”½ ìˆ˜ì§‘
            metas = vectorstore._collection.get(include=["metadatas"])["metadatas"]

            target_grammar = None
            for d in retrieved_docs:
                if d.metadata.get("topic") == candidate_topic:
                    target_grammar = d.metadata.get("grammar_type")
                    break

            related_topics = []
            seen = set()
            for m in metas:
                if not m:
                    continue
                t = m.get("topic")
                if (
                    m.get("grammar_type") == target_grammar
                    and t != asked_topic
                    and t not in seen
                ):
                    related_topics.append((t, m.get("summary", "")))
                    seen.add(t)

            return {
                "type": "definition_missing",
                "topic": asked_topic,
                "related_topics": related_topics[:5],
                "routed": routed,
            }

    # =========================
    # 3. Rerank
    # =========================
    pairs = [(query, doc.page_content) for doc, _ in raw]
    rr_scores = reranker.predict(pairs)

    scored = []
    for (doc, dist), rr in zip(raw, rr_scores):
        final = rr - 0.2 * dist

        doc_role = doc.metadata.get("role")
        if doc_role == role:
            final *= 1.25
        elif role == "definition" and doc_role != "definition":
            final *= 0.95

        scored.append((doc, dist, rr, final))

    scored.sort(key=lambda x: x[3], reverse=True)
    best_doc, best_dist, best_rr, best_final = scored[0]

    # =========================
    # 4. Confidence ê³„ì‚°
    # =========================
    if len(scored) > 1:
        margin = scored[0][3] - scored[1][3]
    else:
        margin = 0.15

    if route_conf == "high":
        m_hi, m_mid = 0.2, 0.08
    else:
        m_hi, m_mid = 0.3, 0.12

    if margin > m_hi:
        confidence = "high"
    elif margin > m_mid:
        confidence = "medium"
    else:
        confidence = "low"

    # =========================
    # 5. ì •ìƒ ì˜ìƒ ë°˜í™˜
    # =========================
    return {
        "type": "video_ok",
        "doc": best_doc,
        "confidence": confidence,
        "final_score": best_final,
        "rerank": best_rr,
        "dist": best_dist,
        "routed": routed,
    }


def youtube_embed(url, start, end):
    if "watch?v=" in url:
        vid = url.split("watch?v=")[1].split("&")[0]
    elif "youtu.be/" in url:
        vid = url.split("youtu.be/")[1].split("?")[0]
    else:
        return None
    return f"https://www.youtube.com/embed/{vid}?start={int(start)}&end={int(end)}"

# =====================
# UI
# =====================
st.set_page_config(page_title="ì˜ì–´ í•™ìŠµ ë„ìš°ë¯¸")

# Custom CSS for chat-like UI
st.markdown("""
<style>
    .message-row {
        display: flex !important;
        margin: 10px 0 !important;
        clear: both !important;
        width: 100% !important;
    }

    .message-row.user {
        justify-content: flex-start !important;
        flex-direction: row-reverse !important;
    }

    .message-row.bot {
        justify-content: flex-start !important;
    }

    .avatar {
        width: 40px !important;
        height: 40px !important;
        min-width: 40px !important;
        border-radius: 50% !important;
        background-color: #E0E0E0 !important;
        display: flex !important;
        align-items: center !important;
        justify-content: center !important;
        font-size: 20px !important;
        margin: 0 10px !important;
    }

    .user-message {
        background-color: #E3F2FD !important;
        padding: 15px 20px !important;
        border-radius: 15px !important;
        max-width: 70% !important;
        width: fit-content !important;
        text-align: right !important;
    }

    .bot-message {
        background-color: #F5F5F5 !important;
        padding: 15px 20px !important;
        border-radius: 15px !important;
        max-width: 80% !important;
        width: fit-content !important;
    }

    .video-card {
        background-color: white;
        border: 1px solid #E0E0E0;
        border-radius: 10px;
        padding: 15px;
        margin: 10px 0;
    }

    .topic-badge {
        display: inline-block;
        background-color: #2196F3;
        color: white;
        padding: 5px 12px;
        border-radius: 15px;
        font-size: 0.85em;
        margin-right: 10px;
    }

    .role-badge {
        display: inline-block;
        background-color: #4CAF50;
        color: white;
        padding: 5px 12px;
        border-radius: 15px;
        font-size: 0.85em;
    }

    /* ì…ë ¥ì°½ ì›ë˜ëŒ€ë¡œ */
    /* ë©”ì‹œì§€ ì˜ì—­ì— í•˜ë‹¨ ì—¬ë°± ì¶”ê°€ */
    .main .block-container {
        padding-bottom: 100px;
    }
</style>
""", unsafe_allow_html=True)
import time
from concurrent.futures import ThreadPoolExecutor
def stream_text(placeholder, text):
    """ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼ë¡œ í…ìŠ¤íŠ¸ ì¶œë ¥"""
    displayed = ""
    for char in text:
        displayed += char
        placeholder.markdown(displayed)
        time.sleep(0.01)
        
st.title("ğŸ“ ì˜ì–´í•™ìŠµë„ìš°ë¯¸")

# Initialize session state
if "messages" not in st.session_state:
    st.session_state.messages = []

# Initialize session state
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display chat history (ì´ì „ ëŒ€í™”ë§Œ)
if len(st.session_state.messages) > 0:
    st.markdown("### ğŸ’¬ ëŒ€í™” ê¸°ë¡")
    for msg in st.session_state.messages:
        if msg.get("role") == "user":
            st.markdown(
                f'''<div class="message-row user">
                    <div class="avatar">ğŸ‘¤</div>
                    <div class="user-message">{msg.get("content", "")}</div>
                </div>''',
                unsafe_allow_html=True
            )
        elif msg.get("role") == "assistant":
            content = msg.get("content", "")
            if content:  # Only display if there's actual content
                st.markdown(
                    f'''<div class="message-row bot">
                        <div class="avatar">ğŸ’¡</div>
                        <div class="bot-message">{content}</div>
                    </div>''',
                    unsafe_allow_html=True
                )
    st.markdown("---")  # êµ¬ë¶„ì„ 

query = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ë¹„ë™ì‚¬ê°€ ë­ì•¼?)")

if query:
    # 1. ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€ (ì„¸ì…˜ì— ì €ì¥)
    st.session_state.messages.append({
        "role": "user",
        "content": query
    })

    # í˜„ì¬ ì§ˆë¬¸ ë§í’ì„ ìœ¼ë¡œ í‘œì‹œ
    st.markdown(
        f'''<div class="message-row user">
            <div class="avatar">ğŸ‘¤</div>
            <div class="user-message">{query}</div>
        </div>''',
        unsafe_allow_html=True
    )

    # âœ… ë³‘ë ¬ ì‹œì‘: ìš”ì•½ ìƒì„± & ì˜ìƒ ê²€ìƒ‰ ë™ì‹œì— ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
    with ThreadPoolExecutor(max_workers=2) as executor:
        summary_future = executor.submit(generate_concept_summary, query)
        video_future = executor.submit(search_video, query)

        # ìš”ì•½ ê²°ê³¼ ë°›ê¸°
        summary = summary_future.result()

        # 2. ìš”ì•½ ìŠ¤íŠ¸ë¦¬ë° (ë§í’ì„  ìŠ¤íƒ€ì¼ë¡œ)
        summary_placeholder = st.empty()

        displayed = ""
        for char in summary:
            displayed += char
            # ë§í’ì„  ìŠ¤íƒ€ì¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°
            summary_html = f'''<div class="message-row bot">
                <div class="avatar">ğŸ¤–</div>
                <div class="bot-message">{displayed}</div>
            </div>'''
            summary_placeholder.markdown(summary_html, unsafe_allow_html=True)
            time.sleep(0.01)

        # ìš”ì•½ ë©”ì‹œì§€ ì €ì¥
        st.session_state.messages.append({
            "role": "assistant",
            "content": summary,
            "type": "summary"
        })
        
        # ì˜ìƒ ê²€ìƒ‰ì´ ì•„ì§ ì•ˆ ëë‚¬ìœ¼ë©´ ëŒ€ê¸°
        with st.spinner("ğŸ”„ ì˜ìƒ ë¡œë”© ì¤‘..."):
            result = video_future.result()
    
    # 4. ì˜ìƒ ê²°ê³¼ ì²˜ë¦¬
    if not result:
        st.error("ê´€ë ¨ ì˜ìƒì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        st.session_state.messages.append({
            "role": "assistant",
            "content": "ê´€ë ¨ ì˜ìƒì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
            "type": "text"
        })
    
    elif result.get("type") == "definition_missing":
        related_text = "\n".join([
            f"- **{t}**: {desc}" 
            for t, desc in result["related_topics"]
        ])
        bot_msg = f"""âš ï¸ **{result['topic']}** ìì²´ë¥¼ ì„¤ëª…í•˜ëŠ” ê°•ì˜ëŠ” ì•„ì§ ì—†ìŠµë‹ˆë‹¤.

### ğŸ“š ëŒ€ì‹ , í˜„ì¬ ì œê³µë˜ëŠ” ê´€ë ¨ ê°•ì˜
{related_text}

ğŸ‘‰ **{result['topic']} (ê¸°ë³¸ ê°œë…)** ê°•ì˜ëŠ” ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤."""
        
        st.warning(bot_msg)
        st.session_state.messages.append({
            "role": "assistant",
            "content": bot_msg,
            "type": "text"
        })
    
    elif result.get("type") == "video_ok":
        doc = result["doc"]
        meta = doc.metadata
        topic = meta.get("topic", "Unknown")

        # ë‹µë³€ì„ ë§í’ì„ ìœ¼ë¡œ í‘œì‹œ
        answer_html = f'''<div class="message-row bot">
            <div class="avatar">ğŸ¤–</div>
            <div class="bot-message"><strong>{topic}</strong></div>
        </div>'''
        st.markdown(answer_html, unsafe_allow_html=True)

        if result['confidence'] == "low":
            st.warning("âš ï¸ ì •í™•ë„ê°€ ë‹¤ì†Œ ë‚®ì„ ìˆ˜ ìˆëŠ” ì¶”ì²œì…ë‹ˆë‹¤.")

        embed_url = youtube_embed(
            meta.get("video_url", ""),
            meta.get("start_time", 0),
            meta.get("end_time", 0)
        )
        if embed_url:
            st.components.v1.iframe(embed_url, width=700, height=400)
        
        st.session_state.messages.append({
            "role": "assistant",
            "type": "video",
            "confidence": result['confidence'],
            "video_data": {
                "topic": topic,
                "url": meta.get("video_url", ""),
                "start": meta.get("start_time", 0),
                "end": meta.get("end_time", 0)
            }
        })