"""
ì˜ì–´ í•™ìŠµ ë„ìš°ë¯¸ v3 - Confidence ê¸°ë°˜ ê°œì„ 
- Knowledge Graph (26ê°œ) + Smart Search v2 (113ê°œ ì „ì²´)
- Threshold ì œê±°, Confidence ê¸°ë°˜ íŒë‹¨
- LLM Judge ê°•í™”
"""

import streamlit as st
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain_openai import ChatOpenAI
from openai import OpenAI
from dotenv import load_dotenv
from rapidfuzz import process, fuzz
import unicodedata
import json
import os

load_dotenv()

st.set_page_config(page_title="ì˜ì–´ í•™ìŠµ ë„ìš°ë¯¸ v3", page_icon="ğŸ“š", layout="wide")

# ============================================================
# ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
# ============================================================

@st.cache_resource
def load_vectorstore():
    embeddings = HuggingFaceEmbeddings(model_name="intfloat/multilingual-e5-large")
    vectorstore = Chroma(
        persist_directory="/data/edutem/sooine/rag_bot/chroma_db",
        embedding_function=embeddings,
    )
    return vectorstore

vectorstore = load_vectorstore()
client = OpenAI()
llm = ChatOpenAI(model="gpt-4o", temperature=0)

# Knowledge Graph ë¡œë“œ
@st.cache_resource
def load_knowledge_graph(_mtime):
    with open('/data/edutem/sooine/rag_bot/knowledge_graph.json', 'r', encoding='utf-8') as f:
        return json.load(f)

kg_path = '/data/edutem/sooine/rag_bot/knowledge_graph.json'
kg_mtime = os.path.getmtime(kg_path)
knowledge_graph = load_knowledge_graph(kg_mtime)

# ============================================================
# Knowledge Graph ê²€ìƒ‰ í•¨ìˆ˜
# ============================================================

def normalize(s):
    return unicodedata.normalize("NFC", s.lower().replace(" ", ""))

def fuzzy_match_topic(query, topic_list):
    q = normalize(query)
    candidates = [normalize(t) for t in topic_list]
    match_result, score, idx = process.extractOne(q, candidates, scorer=fuzz.ratio)
    if score > 70:
        return topic_list[idx]
    return None

def search_in_knowledge_graph(query):
    """ì§€ì‹ ê·¸ë˜í”„ì—ì„œ ê²€ìƒ‰"""
    query_lower = query.lower().strip()
    topic_list = list(knowledge_graph.keys())

    # 1ë‹¨ê³„: ì •í™•í•œ ì¼ì¹˜
    for main_topic in topic_list:
        if main_topic.lower() == query_lower:
            return {"type": "main_topic", "main_topic": main_topic, "data": knowledge_graph[main_topic]}

    # 2ë‹¨ê³„: ë¶€ë¶„ ì¼ì¹˜
    for main_topic in topic_list:
        if query_lower in main_topic.lower() or main_topic.lower() in query_lower:
            return {"type": "main_topic", "main_topic": main_topic, "data": knowledge_graph[main_topic]}

    # 3ë‹¨ê³„: Fuzzy match
    best = fuzzy_match_topic(query, topic_list)
    if best:
        return {"type": "main_topic", "main_topic": best, "data": knowledge_graph[best]}

    return None

# ============================================================
# Query Rewriting
# ============================================================

def rewrite_query(query):
    """ì˜¤íƒ€ êµì • + ë¬¸ë²• í† í”½ ì¶”ì¶œ"""
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{
            "role": "user",
            "content": f"""ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ì˜ì–´ ë¬¸ë²• í† í”½ì„ ì¶”ì¶œí•˜ì„¸ìš”.

ì‚¬ìš©ì ì§ˆë¬¸: {query}

ê·œì¹™:
- í•µì‹¬ ë¬¸ë²• ìš©ì–´ë§Œ ì¶”ì¶œ
- ì˜¤íƒ€ êµì • (ë¹„ë™ì‚¬ â†’ beë™ì‚¬, ë¨¸ì•¼ â†’ ë­ì•¼)
- ì§ˆë¬¸ í˜•ì‹ ì œê±°
- ì˜ˆ: "ë¹„ë™ì‚¬ê°€ ë¨¸ì•¼?" â†’ "beë™ì‚¬"
- ì˜ˆ: "have pp ì–´ë–»ê²Œ ì¨?" â†’ "í˜„ì¬ì™„ë£Œ"

ì¶œë ¥: í† í”½ë§Œ (ì„¤ëª… ì—†ì´)"""
        }],
        max_tokens=50,
        temperature=0
    )
    return response.choices[0].message.content.strip()

# ============================================================
# ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ… í•¨ìˆ˜
# ============================================================

def format_results_with_metadata(results):
    """
    ê²€ìƒ‰ ê²°ê³¼ë¥¼ LLMì´ ì´í•´í•˜ê¸° ì¢‹ì€ í¬ë§·ìœ¼ë¡œ ë³€í™˜
    
    Args:
        results: List of (Document, score) or List of Document
    
    Returns:
        str: í¬ë§·íŒ…ëœ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´
    """
    if not results:
        return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    context_parts = []
    
    for i, item in enumerate(results):
        # score ìˆëŠ”ì§€ í™•ì¸
        if isinstance(item, tuple):
            doc, score = item
        else:
            doc = item
            score = None
        
        # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        topic = doc.metadata.get('topic', 'ì•Œ ìˆ˜ ì—†ìŒ')
        start_time = doc.metadata.get('start_time', 0)
        end_time = doc.metadata.get('end_time', 0)
        video_url = doc.metadata.get('video_url', '')
        
        # ì‹œê°„ í¬ë§· (MM:SS)
        start_str = f"{int(start_time//60)}:{int(start_time%60):02d}"
        end_str = f"{int(end_time//60)}:{int(end_time%60):02d}"
        duration = end_time - start_time
        
        # ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° (200ì)
        content = doc.page_content.replace('\n', ' ')
        if len(content) > 200:
            content_preview = content[:200].rsplit(' ', 1)[0] + "..."
        else:
            content_preview = content
        
        # í¬ë§·íŒ…
        formatted = f"""
[ê²°ê³¼ {i}]
- í† í”½: {topic}
- ì‹œê°„: {start_str} ~ {end_str} ({duration:.0f}ì´ˆ)
{"- ìœ ì‚¬ë„: " + f"{score:.4f}" if score is not None else ""}
- ë‚´ìš©: {content_preview}
"""
        context_parts.append(formatted.strip())
    
    return "\n\n".join(context_parts)

# ============================================================
# Smart Search v2 (ê°œì„ ëœ ë²„ì „)
# ============================================================

def smart_search_v2(query, k=10, rewritten=None):
    """
    Confidence ê¸°ë°˜ ê²€ìƒ‰ (Threshold ì œê±°)
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        k: ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜
        rewritten: ë¯¸ë¦¬ rewriteëœ ì¿¼ë¦¬ (ì˜µì…˜)
    
    Returns:
        dict: ê²€ìƒ‰ ê²°ê³¼ì™€ confidence ì •ë³´
    """
    
    # 1. Rewrite (ì˜¤íƒ€ êµì •)
    if rewritten is None:
        rewritten = rewrite_query(query)
    
    # 2. ê²€ìƒ‰ (score í¬í•¨)
    results = vectorstore.similarity_search_with_score(rewritten, k=k)
    
    if not results:
        return {
            "found": False,
            "confidence": "none",
            "rewritten": rewritten,
            "message": "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.",
            "results": []
        }
    
    # ë¡œê·¸ ì¶œë ¥
    print(f"\n{'='*60}")
    print(f"Query: {query} â†’ Rewritten: {rewritten}")
    for i, (doc, score) in enumerate(results):
        print(f"  {i}. [{score:.3f}] {doc.metadata.get('topic')}")
    
    # 3. ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    context = format_results_with_metadata(results)
    
    # 4. LLM íŒë‹¨ (ê°œì„ ëœ í”„ë¡¬í”„íŠ¸)
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": """ë‹¹ì‹ ì€ ì˜ì–´ ë¬¸ë²• êµìœ¡ ì˜ìƒ ê²€ìƒ‰ ì‹œìŠ¤í…œì˜ íŒë‹¨ìì…ë‹ˆë‹¤.
ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ì— ê°€ì¥ ì í•©í•œ ì˜ìƒì„ ì„ íƒí•˜ì„¸ìš”.

íŒë‹¨ ê¸°ì¤€:
1. **ì •í™•í•œ ì¼ì¹˜** (high confidence): ì§ˆë¬¸ì˜ í•µì‹¬ í† í”½ê³¼ ê²€ìƒ‰ ê²°ê³¼ í† í”½ì´ ì •í™•íˆ ì¼ì¹˜
   ì˜ˆ: "beë™ì‚¬ê°€ ë­ì•¼?" â†’ "beë™ì‚¬" í† í”½
   
2. **ìœ ì‚¬ í† í”½** (medium confidence): ì§ì ‘ ì¼ì¹˜ëŠ” ì—†ì§€ë§Œ ë‹µë³€ ê°€ëŠ¥í•œ ê´€ë ¨ í† í”½
   ì˜ˆ: "ìˆ˜ë™íƒœ ì‹œì œ" ì§ˆë¬¸ â†’ "ìˆ˜ë™íƒœ" í† í”½ (ê¸°ë³¸ ê°œë…ìœ¼ë¡œ ë‹µë³€ ê°€ëŠ¥)
   
3. **ê´€ë ¨ ì—†ìŒ** (low confidence): ì§ˆë¬¸ê³¼ ê´€ë ¨ì„±ì´ ë‚®ê±°ë‚˜ ë„ˆë¬´ ë™ë–¨ì–´ì§
   ì˜ˆ: "ê°€ì •ë²•" ì§ˆë¬¸ â†’ "í˜„ì¬ì™„ë£Œ" í† í”½

**ì¤‘ìš”**: ìœ ì‚¬ë„ ì ìˆ˜ëŠ” ì°¸ê³ ë§Œ í•˜ê³ , í† í”½ëª…ê³¼ ë‚´ìš©ì„ ìš°ì„ ì ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”.
**í† í”½ ì„ íƒ**: ì§ˆë¬¸ì´ "~ê°€ ë­ì•¼?" ê°™ì€ ê¸°ë³¸ ê°œë… ì§ˆë¬¸ì´ë©´, ê²€ìƒ‰ì–´ì™€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ê¸°ë³¸ í† í”½ì„ ì„ íƒí•˜ì„¸ìš”."""
            },
            {
                "role": "user",
                "content": f"""
ì§ˆë¬¸: {query}
ê²€ìƒ‰ì–´: {rewritten}

ê²€ìƒ‰ ê²°ê³¼:
{context}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”:
{{
    "confidence": "high" | "medium" | "low",
    "found": true | false,
    "best_index": 0ë¶€í„° {k-1} ì‚¬ì´ì˜ ìˆ«ì,
    "best_topic": "ì„ íƒí•œ í† í”½ëª…",
    "reasoning": "ì„ íƒ ì´ìœ  (í•œêµ­ì–´ 2-3ë¬¸ì¥)",
    "alternative_topics": ["ê´€ë ¨ìˆì„ ìˆ˜ ìˆëŠ” ë‹¤ë¥¸ í† í”½ë“¤ (ìµœëŒ€ 3ê°œ)"]
}}
"""
            }
        ],
        response_format={"type": "json_object"},
        temperature=0
    )
    
    judgment = json.loads(response.choices[0].message.content)
    
    # 5. ê²°ê³¼ êµ¬ì„±
    best_idx = judgment.get("best_index", 0)
    if best_idx is None or best_idx >= len(results):
        best_idx = 0
    
    best_doc, best_score = results[best_idx]
    
    # confidenceê°€ lowë©´ foundë¥¼ falseë¡œ
    if judgment.get("confidence") == "low":
        judgment["found"] = False
    
    print(f"  â†’ confidence: {judgment.get('confidence')}, found: {judgment.get('found')}, best: {judgment.get('best_topic')}")
    
    return {
        **judgment,
        "rewritten": rewritten,
        "score": best_score,
        "doc": best_doc,
        "video_url": best_doc.metadata.get('video_url'),
        "start_time": best_doc.metadata.get('start_time'),
        "end_time": best_doc.metadata.get('end_time'),
        "results": results
    }

# ============================================================
# ì˜ìƒ ì„ë² ë“œ URL ìƒì„±
# ============================================================

def get_video_embed(url, start, end):
    """YouTube ì„ë² ë“œ URL ìƒì„±"""
    if not url:
        return None
    if "watch?v=" in url:
        video_id = url.split("watch?v=")[-1].split("&")[0]
    elif "youtu.be/" in url:
        video_id = url.split("youtu.be/")[-1].split("?")[0]
    else:
        return None
    return f"https://www.youtube.com/embed/{video_id}?start={int(start)}&end={int(end)}"

# ============================================================
# UI
# ============================================================

st.title("ğŸ“š ì˜ì–´ í•™ìŠµ ë„ìš°ë¯¸ v3")
st.markdown("**ê°œì„ **: Confidence ê¸°ë°˜ íŒë‹¨ (Threshold ì œê±°)")

# ì„¸ì…˜ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")

    # ê²€ìƒ‰ ëª¨ë“œ ì„ íƒ
    search_mode = st.radio(
        "ê²€ìƒ‰ ëª¨ë“œ",
        ["ğŸ” í•˜ì´ë¸Œë¦¬ë“œ (KG ìš°ì„ )", "âš¡ Smart Searchë§Œ"],
        index=0,
        help="í•˜ì´ë¸Œë¦¬ë“œ: KGì—ì„œ ë¨¼ì € ì°¾ê³  ì—†ìœ¼ë©´ Smart Search v2\nSmart Searchë§Œ: ì „ì²´ 113ê°œ í† í”½ ì§ì ‘ ê²€ìƒ‰"
    )

    st.divider()

    # k ê°’ ì¡°ì •
    k_value = st.slider(
        "ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜ (k)",
        min_value=5,
        max_value=20,
        value=10,
        step=1,
        help="ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜ (ë§ì„ìˆ˜ë¡ ì •í™•í•˜ì§€ë§Œ ëŠë¦¼)"
    )

    st.divider()

    # Knowledge Graph ì£¼ì œ í‘œì‹œ
    st.markdown("### ğŸ“š KG ì£¼ì œ")
    st.caption(f"{len(knowledge_graph)}ê°œ")
    with st.expander("ì£¼ì œ ëª©ë¡ ë³´ê¸°"):
        for topic in sorted(knowledge_graph.keys()):
            st.markdown(f"- {topic}")

    st.divider()

    if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state["messages"] = []
        st.rerun()

    st.divider()
    st.markdown("### ğŸ“Š ì‹œìŠ¤í…œ")
    st.markdown("- ChromaDB: 149ê°œ í† í”½, 384 ë¬¸ì„œ")
    st.markdown("- KG: 26ê°œ ì£¼ì œ")
    st.markdown("- LLM: GPT-4o")
    st.markdown("- ë²„ì „: v3 (Confidence ê¸°ë°˜)")

# ì‚¬ìš©ì ì…ë ¥
user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")

if user_input:
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        with st.spinner("ê²€ìƒ‰ ì¤‘..."):

            if "í•˜ì´ë¸Œë¦¬ë“œ" in search_mode:
                # ========== í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ: KG ìš°ì„  â†’ ì—†ìœ¼ë©´ Smart Search v2 ==========
                rewritten = rewrite_query(user_input) 
                kg_result = search_in_knowledge_graph(rewritten)

                if kg_result:
                    # KGì—ì„œ ì°¾ìŒ
                    st.caption("ğŸ” Knowledge Graphì—ì„œ ì°¾ìŒ")
                    main_topic = kg_result['main_topic']

                    # LLM ì„¤ëª…
                    st.markdown(f"## ğŸ’¡ {main_topic}")
                    with st.spinner("ì„¤ëª… ìƒì„± ì¤‘..."):
                        explain_prompt = f"'{main_topic}'ì´ ë¬´ì—‡ì¸ì§€ í•µì‹¬ë§Œ ê°„ë‹¨íˆ 2-3ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
                        explanation = llm.invoke(explain_prompt).content.strip()
                    st.write(explanation)

                    st.markdown("---")
                    st.success(f"âœ… '{main_topic}' ê°•ì˜ê°€ ìˆì–´ìš”!")

                    # Smart Search v2ë¡œ ìµœì  ì˜ìƒ êµ¬ê°„ ì°¾ê¸°
                    search_result = smart_search_v2(main_topic, k=k_value, rewritten=main_topic)
                    
                    confidence = search_result.get("confidence", "low")
                    
                    if confidence in ["high", "medium"]:
                        st.markdown("### ğŸ“º ê°•ì˜ ì˜ìƒ")
                        st.caption(f"ğŸ¯ í™•ì‹ ë„: {confidence} | Score: {search_result.get('score', 0):.3f}")
                        
                        video_url = search_result.get("video_url")
                        start = int(float(search_result.get("start_time", 0)))
                        end = int(float(search_result.get("end_time", 0)))

                        embed_url = get_video_embed(video_url, start, end)
                        if embed_url:
                            st.components.v1.iframe(embed_url, width=800, height=450)
                            st.caption(f"â±ï¸ {start}ì´ˆ ~ {end}ì´ˆ")
                            
                        if search_result.get("reasoning"):
                            with st.expander("ğŸ’¡ ì„ íƒ ì´ìœ "):
                                st.write(search_result["reasoning"])

                        # ê´€ë ¨ ì£¼ì œ
                        st.markdown("---")
                        st.markdown("### ğŸ”— ê´€ë ¨ ì£¼ì œ")
                        shown = {search_result.get("best_topic", "")}
                        for doc, doc_score in search_result.get("results", [])[1:6]:
                            rel_topic = doc.metadata.get("topic", "")
                            if rel_topic and rel_topic not in shown:
                                shown.add(rel_topic)
                                with st.expander(f"âœ… {rel_topic} (score: {doc_score:.3f})"):
                                    rel_url = doc.metadata.get('video_url', '')
                                    rel_start = int(float(doc.metadata.get('start_time', 0)))
                                    rel_end = int(float(doc.metadata.get('end_time', 0)))
                                    rel_embed = get_video_embed(rel_url, rel_start, rel_end)
                                    if rel_embed:
                                        st.components.v1.iframe(rel_embed, width=700, height=400)

                else:
                    # KGì— ì—†ìŒ â†’ Smart Search v2ë¡œ ì „í™˜
                    st.caption("âš¡ KGì— ì—†ìŒ â†’ Smart Search v2 ì‚¬ìš©")
                    result = smart_search_v2(user_input, k=k_value, rewritten=rewritten)

                    keyword = result.get("best_topic", user_input)
                    rewritten_query = result.get("rewritten", "")
                    score = result.get("score", 1.0)
                    confidence = result.get("confidence", "low")

                    st.markdown(f"## ğŸ’¡ {keyword}")
                    st.caption(f"ğŸ” {user_input} â†’ {rewritten_query} â†’ {keyword}")
                    
                    if confidence == "high":
                        st.success(f"âœ… '{keyword}' ê°•ì˜ë¥¼ ì°¾ì•˜ì–´ìš”!")
                        st.caption(f"ğŸ¯ í™•ì‹ ë„: ë†’ìŒ | Score: {score:.3f}")
                        
                    elif confidence == "medium":
                        st.info(f"ğŸŸ¡ '{keyword}' í† í”½ì´ ê´€ë ¨ìˆì„ ìˆ˜ ìˆì–´ìš”")
                        st.caption(f"âš ï¸ í™•ì‹ ë„: ì¤‘ê°„ | Score: {score:.3f}")
                        
                    else:  # low
                        st.warning(f"ğŸ“­ '{keyword}'ì„(ë¥¼) ì§ì ‘ ë‹¤ë£¨ëŠ” ê°•ì˜ëŠ” ì—†ì–´ìš”")
                        st.caption(f"â“ í™•ì‹ ë„: ë‚®ìŒ | Score: {score:.3f}")
                    
                    # ì„ íƒ ì´ìœ  í‘œì‹œ
                    if result.get("reasoning"):
                        with st.expander("ğŸ’¡ íŒë‹¨ ê·¼ê±°"):
                            st.write(result["reasoning"])

                    # ì˜ìƒ í‘œì‹œ (high, mediumì¼ ë•Œë§Œ)
                    if confidence in ["high", "medium"]:
                        video_url = result.get("video_url")
                        start = int(float(result.get("start_time", 0)))
                        end = int(float(result.get("end_time", 0)))

                        if video_url:
                            st.markdown("### ğŸ“º ê°•ì˜ ì˜ìƒ")
                            embed_url = get_video_embed(video_url, start, end)
                            if embed_url:
                                st.components.v1.iframe(embed_url, width=800, height=450)
                                st.caption(f"â±ï¸ {start}ì´ˆ ~ {end}ì´ˆ")

                        # ê´€ë ¨ ì£¼ì œ
                        st.markdown("---")
                        st.markdown("### ğŸ”— ê´€ë ¨ ì£¼ì œ")
                        shown = {keyword}
                        for doc, doc_score in result["results"][1:6]:
                            rel_topic = doc.metadata.get("topic", "")
                            if rel_topic and rel_topic not in shown:
                                shown.add(rel_topic)
                                with st.expander(f"âœ… {rel_topic} (score: {doc_score:.3f})"):
                                    rel_url = doc.metadata.get('video_url', '')
                                    rel_start = int(float(doc.metadata.get('start_time', 0)))
                                    rel_end = int(float(doc.metadata.get('end_time', 0)))
                                    rel_embed = get_video_embed(rel_url, rel_start, rel_end)
                                    if rel_embed:
                                        st.components.v1.iframe(rel_embed, width=700, height=400)
                    
                    # ëŒ€ì²´ í† í”½ ì œì•ˆ (low confidenceì¼ ë•Œ)
                    if confidence == "low" and result.get("alternative_topics"):
                        st.markdown("### ğŸ” ì´ëŸ° í† í”½ë“¤ì„ ì°¾ì•„ë³´ì‹œê² ì–´ìš”?")
                        for alt in result["alternative_topics"]:
                            st.markdown(f"- {alt}")

            else:
                # ========== Smart Search v2ë§Œ ì‚¬ìš© ==========
                result = smart_search_v2(user_input, k=k_value)

                keyword = result.get("best_topic", user_input)
                rewritten = result.get("rewritten", "")
                score = result.get("score", 1.0)
                confidence = result.get("confidence", "low")

                st.markdown(f"## ğŸ’¡ {keyword}")
                st.caption(f"ğŸ” {user_input} â†’ {rewritten} â†’ {keyword}")

                if confidence == "high":
                    st.success(f"âœ… '{keyword}' ê°•ì˜ë¥¼ ì°¾ì•˜ì–´ìš”!")
                    st.caption(f"ğŸ¯ í™•ì‹ ë„: ë†’ìŒ | Score: {score:.3f}")
                    
                elif confidence == "medium":
                    st.info(f"ğŸŸ¡ '{keyword}' í† í”½ì´ ê´€ë ¨ìˆì„ ìˆ˜ ìˆì–´ìš”")
                    st.caption(f"âš ï¸ í™•ì‹ ë„: ì¤‘ê°„ | Score: {score:.3f}")
                    
                else:  # low
                    st.warning(f"ğŸ“­ '{keyword}'ì„(ë¥¼) ì§ì ‘ ë‹¤ë£¨ëŠ” ê°•ì˜ëŠ” ì—†ì–´ìš”")
                    st.caption(f"â“ í™•ì‹ ë„: ë‚®ìŒ | Score: {score:.3f}")
                
                # ì„ íƒ ì´ìœ 
                if result.get("reasoning"):
                    with st.expander("ğŸ’¡ íŒë‹¨ ê·¼ê±°"):
                        st.write(result["reasoning"])

                # ì˜ìƒ (high, mediumë§Œ)
                if confidence in ["high", "medium"]:
                    video_url = result.get("video_url")
                    start = int(float(result.get("start_time", 0)))
                    end = int(float(result.get("end_time", 0)))

                    if video_url:
                        st.markdown("### ğŸ“º ê°•ì˜ ì˜ìƒ")
                        embed_url = get_video_embed(video_url, start, end)
                        if embed_url:
                            st.components.v1.iframe(embed_url, width=800, height=450)
                            st.caption(f"â±ï¸ {start}ì´ˆ ~ {end}ì´ˆ")

                    st.markdown("---")
                    st.markdown("### ğŸ”— ê´€ë ¨ ì£¼ì œ")
                    shown = {keyword}
                    for doc, doc_score in result["results"][1:6]:
                        rel_topic = doc.metadata.get("topic", "")
                        if rel_topic and rel_topic not in shown:
                            shown.add(rel_topic)
                            with st.expander(f"âœ… {rel_topic} (score: {doc_score:.3f})"):
                                rel_url = doc.metadata.get('video_url', '')
                                rel_start = int(float(doc.metadata.get('start_time', 0)))
                                rel_end = int(float(doc.metadata.get('end_time', 0)))
                                rel_embed = get_video_embed(rel_url, rel_start, rel_end)
                                if rel_embed:
                                    st.components.v1.iframe(rel_embed, width=700, height=400)
                
                # ëŒ€ì²´ í† í”½ ì œì•ˆ
                if confidence == "low" and result.get("alternative_topics"):
                    st.markdown("### ğŸ” ì´ëŸ° í† í”½ë“¤ì„ ì°¾ì•„ë³´ì‹œê² ì–´ìš”?")
                    for alt in result["alternative_topics"]:
                        st.markdown(f"- {alt}")