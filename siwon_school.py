import streamlit as st
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
import streamlit.components.v1 as components
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_community.chat_message_histories import ChatMessageHistory
from dotenv import load_dotenv
import openai
import json
import os

load_dotenv()

# ============================================================
# 1. ì´ˆê¸° ì„¤ì •
# ============================================================

st.set_page_config(
    page_title="ì˜ì–´ í•™ìŠµ ë„ìš°ë¯¸",
    page_icon="ğŸ“š",
)

st.title("ğŸ“š ì˜ì–´ í•™ìŠµ ë„ìš°ë¯¸")
st.markdown("ì˜ìƒ ê¸°ë°˜ ë§ì¶¤í˜• í•™ìŠµ ì‹œìŠ¤í…œ")

# ============================================================
# 2. ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ (ìºì‹œ)
# ============================================================

@st.cache_resource
def load_vectorstore():    
    with st.spinner("ë²¡í„°ìŠ¤í† ì–´ ë¡œë”© ì¤‘..."):
            embeddings = HuggingFaceEmbeddings(model_name="intfloat/multilingual-e5-large")
        
        # ì´ë¯¸ ë§Œë“¤ì–´ì§„ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
            vectorstore = Chroma(
            persist_directory="./chroma_db",
            embedding_function=embeddings,
            collection_name="lectures"
            )
    
    return vectorstore

vectorstore = load_vectorstore()

AVAILABLE_TOPICS = """
í˜„ì¬ í•™ìŠµ ê°€ëŠ¥í•œ ì£¼ì œ:
1. ì‹œê°„ ì „ì¹˜ì‚¬ (at, on, in)
2. ì¥ì†Œ ì „ì¹˜ì‚¬ (at, on, in)
3. ì†Œìœ ê²© (my, mine, his)
4. Does he? vs Is he?
5. ìˆ˜ë™íƒœ (be + ê³¼ê±°ë¶„ì‚¬)
6. í˜„ì¬ì™„ë£Œ
7. that ìš©ë²•
8. I'm not used to íŒ¨í„´
9. Do you? vs Are you?
"""
# ============================================================
# ì„¸ì…˜ ì €ì¥ì†Œ
# ============================================================

if "store" not in st.session_state:
    st.session_state["store"] = {}
    
# ì„¸ì…˜ ID
if "session_id" not in st.session_state:
    st.session_state["session_id"] = "default_user"
    
if "messages" not in st.session_state:
    st.session_state["messages"] = []

if "mode" not in st.session_state:
    st.session_state["mode"] = "search"

def get_session_history(session_id):
    if session_id not in st.session_state["store"]:
        st.session_state["store"][session_id] = ChatMessageHistory()
    return st.session_state["store"][session_id]

# ============================================================
# ì²´ì¸ ìƒì„±
# ============================================================

prompt = ChatPromptTemplate.from_messages([
    ("system", """ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì˜ì–´ í•™ìŠµ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.

    ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ë‹µë³€í•´ì£¼ê³ ,
    ê°•ì˜ì—ì„œ ì„¤ëª…í•œ í•µì‹¬ ë‚´ìš©ê³¼ ì˜ˆì‹œë¥¼ í¬í•¨í•´ì„œ 3-5ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
    ëŒ€ë‹µí•  ë• í•œêµ­ë§ë¡œ í•˜ì„¸ìš”
        """),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", """ê°•ì˜ ë‚´ìš©:
        {context}

        ì§ˆë¬¸: {question}""")
])

llm = ChatOpenAI(model="gpt-4o", temperature=0)
chain = prompt | llm

chain_with_history = RunnableWithMessageHistory(
    chain,
    get_session_history,
    input_messages_key="question",
    history_messages_key="chat_history"
)

# ============================================================
# 3. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ============================================================


# ============================================================
# 4. ì‚¬ì´ë“œë°”
# ============================================================

with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    
    # ëª¨ë“œ ì„ íƒ
    mode = st.radio(
        "ëª¨ë“œ ì„ íƒ",
        ["ğŸ” Search (ê²€ìƒ‰)", "ğŸ“ Quiz (ë¬¸ì œ)", "ğŸ“– Review (ë³µìŠµ)"],
        index=0
    )
    
    if "Search" in mode:
        st.session_state["mode"] = "search"
    elif "Quiz" in mode:
        st.session_state["mode"] = "quiz"
    elif "Review" in mode:
        st.session_state["mode"] = "review"
    
    st.divider()
    
      # ê°€ìš© ì£¼ì œ
    st.markdown("### ğŸ“š í˜„ì¬ í•™ìŠµ ê°€ëŠ¥í•œ ì£¼ì œ")
    st.markdown("""
            - ì‹œê°„ ì „ì¹˜ì‚¬ (at, on, in)
            - ì¥ì†Œ ì „ì¹˜ì‚¬ (at, on, in)
            - ì†Œìœ ê²© (my, mine, his)
            - Does he? vs Is he?
            - ìˆ˜ë™íƒœ (be + ê³¼ê±°ë¶„ì‚¬)
            - í˜„ì¬ì™„ë£Œ
            - that ìš©ë²•
            - I'm not used to íŒ¨í„´
            - Do you? vs Are you?
    """)
    
    st.divider()
    
    # ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state["messages"] = []
        st.rerun()
    
    st.divider()
    

# ============================================================
# 5. ë©”ì¸ ì˜ì—­
# ============================================================

session_id = st.session_state["session_id"]
# ëŒ€í™” ê¸°ë¡ í‘œì‹œ
history = get_session_history(session_id)
for msg in reversed(history.messages):
    role = "user" if msg.type == "human" else "assistant"
    with st.chat_message(role):
        st.markdown(msg.content)
        

# ì‚¬ìš©ì ì…ë ¥    
user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")
 
if user_input:      
    with st.chat_message("user"):
        st.markdown(user_input)
    
    # AI ì‘ë‹µ
    with st.chat_message("assistant"):
        with st.spinner("ê²€ìƒ‰ ì¤‘..."):
            
            # ============================================================
            # Search ëª¨ë“œ
            # ============================================================
            if st.session_state["mode"] == "search":
                
                results_with_scores = vectorstore.similarity_search_with_score(user_input, k=3)
                # ê´€ë ¨ë„ í•„í„°ë§
                
                # ì²« ë²ˆì§¸ ì ìˆ˜ í™•ì¸
                if results_with_scores and results_with_scores[0][1] < 0.30:
                    # ê´€ë ¨ ìˆìŒ
                    relevant_results = [
                        (doc, score) for doc, score in results_with_scores 
                        if score < 0.6
                    ]
                    print(relevant_results)
                    if relevant_results:
                        relevant_docs = [doc for doc, score in relevant_results]
                        context = "\n\n".join([doc.page_content for doc in relevant_docs])
                        
                        # ë‹µë³€ ìƒì„±
                        response = chain_with_history.invoke(
                            {"context": context, 
                                "question": user_input},
                            config={"configurable": {"session_id": session_id}}
                        )
                        
                        st.markdown("ğŸ’¡ **ì„¤ëª…:**")
                        st.markdown(response.content)
                        
                        st.markdown("---")
                        st.markdown("ğŸ“º **ê´€ë ¨ ì˜ìƒ:**")
                        
                        for doc in relevant_docs:
                            url = doc.metadata['video_url']
                            start = int(float(doc.metadata.get("start_time", 0)))
                            # URLì—ì„œ video_id ì¶”ì¶œ
                            if "watch?v=" in url:
                                video_id = url.split("watch?v=")[-1].split("&")[0]
                            elif "youtu.be/" in url:
                                video_id = url.split("youtu.be/")[-1].split("?")[0]
                            else:
                                video_id = url  # fallback

                            embed_url = f"https://www.youtube.com/embed/{video_id}?start={start}"
                            st.components.v1.iframe(embed_url, width=800, height=500)
                        st.session_state["context"] = context
                    else:
                        st.warning("ê´€ë ¨ ìë£Œ ì—†ìŒ")
                else:
                    # ê´€ë ¨ ì—†ìŒ
                    st.warning("âš ï¸ í•´ë‹¹ ë‚´ìš©ì€ ê°•ì˜ ìë£Œì— ì—†ìŠµë‹ˆë‹¤.")
                    with st.expander("ğŸ“š í•™ìŠµ ê°€ëŠ¥í•œ ì£¼ì œ", expanded=True):
                        st.markdown(AVAILABLE_TOPICS)
                                #st.link_button(
                                #    "â–¶ï¸ ì¬ìƒ", 
                                #    f"{url}&t={start}s"
                                #)
                            
            # ============================================================
            # Quiz ëª¨ë“œ
            # ============================================================
            elif st.session_state["mode"] == "quiz":
                history = get_session_history(session_id)
                past_text = "\n".join([m.content for m in history.messages if m.type == "human"])
                num_questions = 5
                context = st.session_state.get("context", "")
                quiz_prompt = ChatPromptTemplate.from_messages([
                        ("system", "ë„ˆëŠ” ì¹œì ˆí•œ ì˜ì–´ ì„ ìƒë‹˜ì´ì•¼."),
                        ("human", """ì§€ê¸ˆê¹Œì§€ ì‚¬ìš©ìê°€ í•™ìŠµ ì¤‘ ë¬¼ì–´ë³¸ ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ì•„:
                    {past_text}

                    ì´ ë‚´ìš©ì„ ì°¸ê³ í•´ì„œ ì•„ë˜ {num_questions}ê°œì˜ ê°ê´€ì‹ ë¬¸ì œë¥¼ ë§Œë“¤ì–´ì¤˜ ë¬¸ì œëŠ” í•œê¸€ë¡œ.

                    {context}

                    ì¶œë ¥ í˜•ì‹(JSON):
                    {{
                        "questions": [
                            {{
                                "question": "ë¬¸ì œ",
                                "options": ["1. ë‹µ1", "2. ë‹µ2", "3. ë‹µ3", "4. ë‹µ4"],
                                "answer": 1
                            }}
                        ]
                    }}
                    """)
                    ])
                
                quiz_chain = quiz_prompt | llm
                quiz = quiz_chain.invoke({
                    "past_text": past_text,  
                    "context": context,  
                    "num_questions": 5    
                })

                import re
                def safe_json_parse(text: str):
                    """LangChain ì‘ë‹µì—ì„œ JSON ë³¸ë¬¸ë§Œ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ"""
                    if not text or not text.strip():
                        raise ValueError("ë¹ˆ ì‘ë‹µì…ë‹ˆë‹¤.")
                    # ì½”ë“œíœìŠ¤ ì œê±°
                    if text.startswith("```"):
                        text = re.sub(r"^```(?:json)?", "", text)
                        text = re.sub(r"```$", "", text)
                    # JSON ë¸”ë¡ë§Œ ì¶”ì¶œ
                    m = re.search(r"\{[\s\S]*\}", text)
                    if not m:
                        raise ValueError("JSON ê°ì²´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return json.loads(m.group(0))
                
                quiz_json = safe_json_parse(getattr(quiz, "content", ""))
                            
                st.title("ğŸ§© ì˜ì–´ í€´ì¦ˆ")

                # ì„¸ì…˜ì— ì‚¬ìš©ì ë‹µì•ˆ ì €ì¥
                if "user_answers" not in st.session_state:
                    st.session_state.user_answers = {}

                # ë¬¸ì œ ë Œë”ë§
                for i, q in enumerate(quiz_json["questions"], 1):
                    st.markdown(f"**Q{i}. {q['question']}**")
                    selected = st.radio(
                        label="",
                        options=[f"{j+1}. {opt}" for j, opt in enumerate(q["options"])],
                        key=f"q{i}"
                    )
                    st.session_state.user_answers[i] = selected
            
            # ============================================================
            # Review ëª¨ë“œ
            # ============================================================
            elif st.session_state["mode"] == "review":
                st.markdown("ğŸ“– **ë³µìŠµ ìë£Œ**")
 