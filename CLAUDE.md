# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

This is a Korean English learning assistant (영어 학습 도우미) powered by RAG (Retrieval-Augmented Generation). The system uses video transcripts from YouTube English lessons, stores them in a vector database, and provides contextual answers with linked video segments.

**Key Technologies:**
- **LangChain** for RAG pipeline and chat history
- **ChromaDB** for vector storage
- **OpenAI GPT-4o** for LLM responses
- **Streamlit** for web UI
- **HuggingFace Embeddings** (intfloat/multilingual-e5-large)

## Development Commands

### Environment Setup
```bash
# Install dependencies using Poetry
poetry install

# Activate virtual environment
poetry shell
```

### Running the Application
```bash
# Main Streamlit application
streamlit run app.py

# Alternative/MVP version
streamlit run siwon_school.py
```

### Knowledge Base Management
```bash
# Build knowledge graph from video transcripts
python video_knowledge_extractor.py
```

## Architecture

### Data Pipeline

1. **Raw Data**: YouTube video transcripts stored in `youtube_playlist/` as JSON files
   - Each file contains segments with `start`, `end`, `text` fields
   - Filenames map to video URLs in `video_knowledge_extractor.py:video_url_map`

2. **Knowledge Graph**: Generated by `video_knowledge_extractor.py`
   - Extracts topics, sub-topics, examples, and video segments using GPT-4o
   - Output: `knowledge_graph.json` with hierarchical structure
   - Structure: `{main_topic: {sub_topics: {id, title, concept, examples, video_segments}}}`

3. **Vector Store**: ChromaDB instance in `chroma_db/`
   - Uses multilingual embeddings (intfloat/multilingual-e5-large)
   - Stores segmented lecture transcripts with metadata (video_url, start_time, topic)

### Application Flow (app.py)

The system has three modes controlled by session state:

#### Search Mode
1. **Question Analysis**: Uses GPT-4o-mini to classify questions as "broad" or "specific"
2. **Broad Questions** (e.g., "be동사가 뭐야?"):
   - Queries knowledge graph directly
   - Displays topic overview with expandable sub-topics
   - Shows embedded YouTube videos with specific time ranges
3. **Specific Questions** (e.g., "I am busy는 맞는 문장이야?"):
   - Performs vector similarity search (k=5)
   - Generates answer using RAG chain with chat history
   - Displays relevant video segments with embeddings

#### Quiz Mode
- Generates multiple-choice questions based on user's chat history
- Uses context from previous search interactions

#### Review Mode
- Placeholder for future implementation

### Key Components

**RAG Chain** ([app.py:159-182](app.py#L159-L182)):
```python
rag_chain = (
    {context: retriever, question: input, chat_history: history}
    | prompt
    | llm
    | StrOutputParser()
)
```

**Question Analysis** ([app.py:113-156](app.py#L113-L156)):
- Uses GPT-4o-mini to determine question intent
- Returns JSON: `{question_type, main_topic, confidence}`
- Confidence threshold of 0.6 determines routing

**Knowledge Extraction** ([video_knowledge_extractor.py:79-137](video_knowledge_extractor.py#L79-L137)):
- Processes video transcripts with GPT-4o
- Extracts structured knowledge using JSON schema
- Handles Unicode normalization for filename matching

## Important Configuration

### Environment Variables (.env)
- `OPENAI_API_KEY`: Required for GPT-4o/4o-mini API calls
- **SECURITY NOTE**: The .env file contains a hardcoded API key and should be gitignored

### Vector Store Collection
- app.py: No explicit collection name (uses default)
- siwon_school.py: Uses collection name "lectures"
- **Ensure consistency** when switching between versions

### Video URL Mapping
Video URLs are hardcoded in `video_knowledge_extractor.py:video_url_map` (lines 14-45). When adding new videos:
1. Add entry to `video_url_map` with exact filename match
2. Use Unicode normalization if filename contains special characters
3. Rebuild knowledge graph with `python video_knowledge_extractor.py`

## Data Structure Notes

### Vector Store Documents
- `page_content`: Transcript segment text
- `metadata`:
  - `video_url`: YouTube URL
  - `start_time`: Segment start (float seconds)
  - `topic`: Main topic label

### Knowledge Graph Schema
```json
{
  "main_topic": {
    "definition": "...",
    "sub_topics": {
      "sub_id": {
        "title": "...",
        "concept": "...",
        "examples": ["..."],
        "video_segments": [
          {
            "video_url": "...",
            "start_time": 28.5,
            "end_time": 46.0,
            "description": "..."
          }
        ]
      }
    },
    "videos": [...]
  }
}
```

## Session Management

Streamlit session state keys:
- `store`: Chat message histories per session
- `session_id`: Current user session ID (default: "default_user")
- `messages`: Display messages
- `mode`: Current mode ("search", "quiz", "review")
- `context`: Last retrieved context for quiz generation
- `user_answers`: Quiz answer tracking

## Common Issues

1. **ChromaDB Collection Mismatch**: app.py and siwon_school.py use different collection names
2. **Unicode Filename Issues**: Video filenames may have NFC/NFD variations; use normalization in `video_knowledge_extractor.py:normalize_filename`
3. **API Key Management**: Hardcoded keys in siwon_school.py (line 14) should be moved to .env
4. **JSON Parsing**: LLM responses may include markdown code fences; use `safe_json_parse` helper
5. **Similarity Threshold**: siwon_school.py uses 0.30 threshold (line 195); adjust based on recall/precision needs

## File Organization

- `app.py`: Main application with knowledge graph navigation
- `siwon_school.py`: Simpler version without knowledge graph
- `siwon_school_mvp.py`: Minimal viable product version
- `video_knowledge_extractor.py`: Knowledge graph builder
- `youtube_playlist/`: Raw video transcript JSON files
- `chroma_db/`: Persistent vector store
- `knowledge_graph.json`: Pre-built topic hierarchy
- `test1104.ipynb`: Development notebook
