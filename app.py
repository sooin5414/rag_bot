import streamlit as st
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
import streamlit.components.v1 as components
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableLambda
from dotenv import load_dotenv
import openai
import json
import os

load_dotenv()

# ============================================================
# 1. ì´ˆê¸° ì„¤ì •
# ============================================================

st.set_page_config(
    page_title="ì˜ì–´ í•™ìŠµ ë„ìš°ë¯¸",
    page_icon="ğŸ“š",
)

st.title("ğŸ“š ì˜ì–´ í•™ìŠµ ë„ìš°ë¯¸")
st.markdown("ì˜ìƒ ê¸°ë°˜ ë§ì¶¤í˜• í•™ìŠµ ì‹œìŠ¤í…œ")

# ============================================================
# 2. ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ (ìºì‹œ)
# ============================================================

@st.cache_resource
def load_vectorstore():    
    with st.spinner("ë²¡í„°ìŠ¤í† ì–´ ë¡œë”© ì¤‘..."):
            embeddings = HuggingFaceEmbeddings(model_name="intfloat/multilingual-e5-large")
        
        # ì´ë¯¸ ë§Œë“¤ì–´ì§„ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
            vectorstore = Chroma(
            persist_directory="./chroma_db",
            embedding_function=embeddings,
            )
    
    return vectorstore

vectorstore = load_vectorstore()
retriever = vectorstore.as_retriever(search_kwargs={"k":5})

# ì§€ì‹ ê·¸ë˜í”„ ë¡œë“œ
@st.cache_resource
def load_knowledge_graph():
    with open('/data/edutem/sooine/rag_bot/knowledge_graph.json', 'r', encoding='utf-8') as f:
        return json.load(f)

knowledge_graph = load_knowledge_graph()

AVAILABLE_TOPICS = """
í˜„ì¬ í•™ìŠµ ê°€ëŠ¥í•œ ì£¼ì œ:
1.
2.
3.
4.
5.
6.
7.
"""

# ============================================================
# ì§€ì‹ ê·¸ë˜í”„ ê²€ìƒ‰ í•¨ìˆ˜
# ============================================================

def search_in_knowledge_graph(query):
    """
    ì§€ì‹ ê·¸ë˜í”„ì—ì„œ í‚¤ì›Œë“œ/ì§ˆë¬¸ ê²€ìƒ‰

    ë°˜í™˜ê°’:
    {
        "type": "main_topic" | "sub_topic" | None,
        "main_topic": "ì£¼ì œëª…",
        "sub_topic_id": "ì„œë¸Œí† í”½ ID" (sub_topicì¸ ê²½ìš°),
        "data": {...}
    }
    """
    query_lower = query.lower().strip()

    # 1ë‹¨ê³„: Main topic ì™„ì „ ì¼ì¹˜
    for main_topic in knowledge_graph.keys():
        if main_topic.lower() == query_lower:
            return {
                "type": "main_topic",
                "main_topic": main_topic,
                "data": knowledge_graph[main_topic]
            }

    # 2ë‹¨ê³„: Main topic ë¶€ë¶„ ì¼ì¹˜
    for main_topic in knowledge_graph.keys():
        if query_lower in main_topic.lower() or main_topic.lower() in query_lower:
            return {
                "type": "main_topic",
                "main_topic": main_topic,
                "data": knowledge_graph[main_topic]
            }

    # 3ë‹¨ê³„: Sub-topic ê²€ìƒ‰ (title, concept, examples)
    best_match = None
    max_score = 0

    for main_topic, topic_data in knowledge_graph.items():
        for sub_id, sub_data in topic_data['sub_topics'].items():
            score = 0

            # title ë§¤ì¹­
            if query_lower in sub_data['title'].lower():
                score += 3

            # concept ë§¤ì¹­
            if query_lower in sub_data['concept'].lower():
                score += 2

            # examples ë§¤ì¹­
            for example in sub_data.get('examples', []):
                if query_lower in example.lower():
                    score += 1
                    break

            if score > max_score:
                max_score = score
                best_match = {
                    "type": "sub_topic",
                    "main_topic": main_topic,
                    "sub_topic_id": sub_id,
                    "data": sub_data,
                    "score": score
                }

    # ë§¤ì¹­ ì ìˆ˜ê°€ 1 ì´ìƒì´ë©´ ë°˜í™˜
    if best_match and max_score >= 1:
        return best_match

    # 4ë‹¨ê³„: ë§¤ì¹­ ì‹¤íŒ¨
    return None

# ============================================================
# ì„¸ì…˜ ì €ì¥ì†Œ
# ============================================================

if "store" not in st.session_state:
    st.session_state["store"] = {}
    
# ì„¸ì…˜ ID
if "session_id" not in st.session_state:
    st.session_state["session_id"] = "default_user"
    
if "messages" not in st.session_state:
    st.session_state["messages"] = []

if "mode" not in st.session_state:
    st.session_state["mode"] = "search"

def get_session_history(session_id):
    if session_id not in st.session_state["store"]:
        st.session_state["store"][session_id] = ChatMessageHistory()
    return st.session_state["store"][session_id]

# ============================================================
# ì²´ì¸ ìƒì„±
# ============================================================

llm = ChatOpenAI(model="gpt-4o", temperature=0)
prompt = ChatPromptTemplate.from_messages([
        ("system", """ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì˜ì–´ í•™ìŠµ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
    
        ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”:
        {context}

        ì´ì „ ëŒ€í™” ê¸°ë¡:
        {chat_history}

        ë‹µë³€ì€ ì¹œì ˆí•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•˜ì„¸ìš”."""),
            ("human", "{question}")
        ])


def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)
    
# RAG ì²´ì¸
rag_chain = (
    {
        "context": lambda x: format_docs(retriever.invoke(x["question"])),
        "question": lambda x: x["question"],
        "chat_history": lambda x: x["chat_history"]
    }
    | prompt
    | llm
    | StrOutputParser()
)

def rag_with_chain(inputs):
    docs = retriever.invoke(inputs["question"])
    
    answer = (prompt | llm | StrOutputParser()).invoke({
        "context" : format_docs(docs),
        "question" : inputs["question"],
        "chat_history" : inputs["chat_history"]
    })
    return {"answer": answer, "source_docs": docs}


rag_chain = RunnableLambda(rag_with_chain) 

chain_with_history = RunnableWithMessageHistory(
    rag_chain,
    get_session_history,
    input_messages_key="question",
    history_messages_key="chat_history"
)

# ============================================================
# 3. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ============================================================


# ============================================================
# 4. ì‚¬ì´ë“œë°”
# ============================================================

with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    
    # ëª¨ë“œ ì„ íƒ
    mode = st.radio(
        "ëª¨ë“œ ì„ íƒ",
        ["ğŸ” Search (ê²€ìƒ‰)", "ğŸ“ Quiz (ë¬¸ì œ)", "ğŸ“– Review (ë³µìŠµ)"],
        index=0
    )
    
    if "Search" in mode:
        st.session_state["mode"] = "search"
    elif "Quiz" in mode:
        st.session_state["mode"] = "quiz"
    elif "Review" in mode:
        st.session_state["mode"] = "review"
    
    st.divider()
    
      # ê°€ìš© ì£¼ì œ
    st.markdown("### ğŸ“š í˜„ì¬ í•™ìŠµ ê°€ëŠ¥í•œ ì£¼ì œ")
    st.markdown("""
            - ì‹œê°„ ì „ì¹˜ì‚¬ (at, on, in)
            - ì¥ì†Œ ì „ì¹˜ì‚¬ (at, on, in)
            - ì†Œìœ ê²© (my, mine, his)
            - Does he? vs Is he?
            - ìˆ˜ë™íƒœ (be + ê³¼ê±°ë¶„ì‚¬)
            - í˜„ì¬ì™„ë£Œ
            - that ìš©ë²•
            - I'm not used to íŒ¨í„´
            - Do you? vs Are you?
    """)
    
    st.divider()
    
    # ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state["messages"] = []
        st.rerun()
    
    st.divider()
    

# ============================================================
# 5. ë©”ì¸ ì˜ì—­
# ============================================================

session_id = st.session_state["session_id"]
# ëŒ€í™” ê¸°ë¡ í‘œì‹œ
history = get_session_history(session_id)
for msg in reversed(history.messages):
    role = "user" if msg.type == "human" else "assistant"
    with st.chat_message(role):
        st.markdown(msg.content)
        

# ì‚¬ìš©ì ì…ë ¥    
user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")
 
if user_input:      
    with st.chat_message("user"):
        st.markdown(user_input)
    
    # AI ì‘ë‹µ
    with st.chat_message("assistant"):
        with st.spinner("ê²€ìƒ‰ ì¤‘..."):
            
            # ============================================================
            # Search ëª¨ë“œ
            # ============================================================
            if st.session_state["mode"] == "search":

                # 1ë‹¨ê³„: ì§€ì‹ ê·¸ë˜í”„ì—ì„œ ë¨¼ì € ê²€ìƒ‰
                kg_result = search_in_knowledge_graph(user_input)

                if kg_result:
                    # ========== ì§€ì‹ ê·¸ë˜í”„ì—ì„œ ì°¾ìŒ ==========

                    if kg_result['type'] == 'main_topic':
                        # Main topic ì „ì²´ í‘œì‹œ
                        main_topic = kg_result['main_topic']
                        topic_data = kg_result['data']

                        st.success(f"âœ… ì§€ì‹ ê·¸ë˜í”„ì—ì„œ ì°¾ì•˜ì–´ìš”: **{main_topic}**")
                        st.markdown(f"## ğŸ“š {main_topic}")
                        st.write(f"{main_topic}ì— ëŒ€í•´ ì•Œì•„ë³¼ê¹Œìš”?")

                        sub_topics = topic_data['sub_topics']

                        st.markdown("---")
                        st.markdown("### ğŸ” ì„¸ë¶€ ì£¼ì œë¥¼ ì„ íƒí•˜ì„¸ìš”")

                        # ê° ì„œë¸Œí† í”½ì„ expanderë¡œ í‘œì‹œ
                        for sub_id, sub_data in sub_topics.items():
                            with st.expander(f"â–¶ï¸ {sub_data['title']}"):
                                st.write(sub_data['concept'])

                                # ì˜ˆë¬¸
                                if sub_data.get('examples'):
                                    st.markdown("**ì˜ˆë¬¸:**")
                                    for ex in sub_data['examples']:
                                        st.write(f"- {ex}")

                                # ê´€ë ¨ ì˜ìƒ
                                if sub_data.get('video_segments'):
                                    st.markdown("**ğŸ“º ê´€ë ¨ ì˜ìƒ:**")
                                    for idx, seg in enumerate(sub_data['video_segments'][:3]):  # ìµœëŒ€ 3ê°œ
                                        url = seg['video_url']
                                        start = int(float(seg.get('start_time', 0)))
                                        end = int(float(seg.get('end_time', 0)))
                                        desc = seg.get('description', '')

                                        # video_id ì¶”ì¶œ
                                        if "watch?v=" in url:
                                            video_id = url.split("watch?v=")[-1].split("&")[0]
                                        elif "youtu.be/" in url:
                                            video_id = url.split("youtu.be/")[-1].split("?")[0]
                                        else:
                                            video_id = url  # fallback

                                        embed_url = f"https://www.youtube.com/embed/{video_id}?start={start}&end={end}"
                                        st.components.v1.iframe(embed_url, width=800, height=450)

                    elif kg_result['type'] == 'sub_topic':
                        # Sub-topicë§Œ ì§‘ì¤‘ í‘œì‹œ
                        main_topic = kg_result['main_topic']
                        sub_data = kg_result['data']

                        st.success(f"âœ… ì§€ì‹ ê·¸ë˜í”„ì—ì„œ ì°¾ì•˜ì–´ìš”: **{main_topic}** > {sub_data['title']}")
                        st.markdown(f"## ğŸ“š {sub_data['title']}")
                        st.write(f"**ì£¼ì œ:** {main_topic}")

                        st.markdown("---")
                        st.markdown("### ğŸ’¡ ê°œë…")
                        st.write(sub_data['concept'])

                        # ì˜ˆë¬¸
                        if sub_data.get('examples'):
                            st.markdown("### ğŸ“ ì˜ˆë¬¸")
                            for ex in sub_data['examples']:
                                st.write(f"- {ex}")

                        # ê´€ë ¨ ì˜ìƒ
                        if sub_data.get('video_segments'):
                            st.markdown("---")
                            st.markdown("### ğŸ“º ê´€ë ¨ ì˜ìƒ")
                            for idx, seg in enumerate(sub_data['video_segments'][:5]):  # ìµœëŒ€ 5ê°œ
                                url = seg['video_url']
                                start = int(float(seg.get('start_time', 0)))
                                end = int(float(seg.get('end_time', 0)))
                                desc = seg.get('description', '')

                                st.write(f"**{idx+1}. {desc}** ({start}ì´ˆ ~ {end}ì´ˆ)")

                                # video_id ì¶”ì¶œ
                                if "watch?v=" in url:
                                    video_id = url.split("watch?v=")[-1].split("&")[0]
                                elif "youtu.be/" in url:
                                    video_id = url.split("youtu.be/")[-1].split("?")[0]
                                else:
                                    video_id = url  # fallback

                                embed_url = f"https://www.youtube.com/embed/{video_id}?start={start}&end={end}"
                                st.components.v1.iframe(embed_url, width=800, height=450)

                else:
                    # ========== ì§€ì‹ ê·¸ë˜í”„ì— ì—†ìŒ â†’ ë²¡í„° ê²€ìƒ‰ ==========
                    st.info("ğŸ” ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤...")

                    with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                        result = chain_with_history.invoke(
                            {"question": user_input},
                            config={"configurable": {"session_id": session_id}}
                        )

                    st.markdown("### ğŸ’¡ ì„¤ëª…")
                    st.write(result["answer"])

                    st.markdown("---")
                    st.markdown("### ğŸ“º ê´€ë ¨ ì˜ìƒ")

                    for i, doc in enumerate(result["source_docs"][:3], 1):
                        topic = doc.metadata.get('topic', 'ê°•ì˜')
                        url = doc.metadata.get('video_url', '#')
                        start = int(float(doc.metadata.get("start_time", 0)))

                        st.write(f"**{i}. {topic}**")
                        st.write(doc.page_content[:200] + "...")

                        # URLì—ì„œ video_id ì¶”ì¶œ
                        if "watch?v=" in url:
                            video_id = url.split("watch?v=")[-1].split("&")[0]
                        elif "youtu.be/" in url:
                            video_id = url.split("youtu.be/")[-1].split("?")[0]
                        else:
                            video_id = url  # fallback

                        embed_url = f"https://www.youtube.com/embed/{video_id}?start={start}"
                        st.components.v1.iframe(embed_url, width=800, height=500)

                        if url != '#':
                            video_url_with_time = f"{url}&t={start}s"
                            st.markdown(f"[â–¶ï¸ ì˜ìƒ ë³´ê¸° ({start}ì´ˆ)]({video_url_with_time})")            
              
                #st.session_state["context"] = context
            #else:
            #    st.warning("âš ï¸ í•´ë‹¹ ë‚´ìš©ì€ ê°•ì˜ ìë£Œì— ì—†ìŠµë‹ˆë‹¤.")
            #    with st.expander("ğŸ“š í•™ìŠµ ê°€ëŠ¥í•œ ì£¼ì œ", expanded=True):
            #        st.markdown(AVAILABLE_TOPICS)
                            #st.link_button(
                            #    "â–¶ï¸ ì¬ìƒ", 
                            #    f"{url}&t={start}s"
                            #)
                        
            # ============================================================
            # Quiz ëª¨ë“œ
            # ============================================================
            elif st.session_state["mode"] == "quiz":
                history = get_session_history(session_id)
                past_text = "\n".join([m.content for m in history.messages if m.type == "human"])
                num_questions = 5
                context = st.session_state.get("context", "")
                quiz_prompt = ChatPromptTemplate.from_messages([
                        ("system", "ë„ˆëŠ” ì¹œì ˆí•œ ì˜ì–´ ì„ ìƒë‹˜ì´ì•¼."),
                        ("human", """ì§€ê¸ˆê¹Œì§€ ì‚¬ìš©ìê°€ í•™ìŠµ ì¤‘ ë¬¼ì–´ë³¸ ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ì•„:
                    {past_text}

                    ì´ ë‚´ìš©ì„ ì°¸ê³ í•´ì„œ ì•„ë˜ {num_questions}ê°œì˜ ê°ê´€ì‹ ë¬¸ì œë¥¼ ë§Œë“¤ì–´ì¤˜ ë¬¸ì œëŠ” í•œê¸€ë¡œ.

                    {context}

                    ì¶œë ¥ í˜•ì‹(JSON):
                    {{
                        "questions": [
                            {{
                                "question": "ë¬¸ì œ",
                                "options": ["1. ë‹µ1", "2. ë‹µ2", "3. ë‹µ3", "4. ë‹µ4"],
                                "answer": 1
                            }}
                        ]
                    }}
                    """)
                    ])
                
                quiz_chain = quiz_prompt | llm
                quiz = quiz_chain.invoke({
                    "past_text": past_text,  
                    "context": context,  
                    "num_questions": 5    
                })

                import re
                def safe_json_parse(text: str):
                    """LangChain ì‘ë‹µì—ì„œ JSON ë³¸ë¬¸ë§Œ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ"""
                    if not text or not text.strip():
                        raise ValueError("ë¹ˆ ì‘ë‹µì…ë‹ˆë‹¤.")
                    # ì½”ë“œíœìŠ¤ ì œê±°
                    if text.startswith("```"):
                        text = re.sub(r"^```(?:json)?", "", text)
                        text = re.sub(r"```$", "", text)
                    # JSON ë¸”ë¡ë§Œ ì¶”ì¶œ
                    m = re.search(r"\{[\s\S]*\}", text)
                    if not m:
                        raise ValueError("JSON ê°ì²´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return json.loads(m.group(0))
                
                quiz_json = safe_json_parse(getattr(quiz, "content", ""))
                            
                st.title("ğŸ§© ì˜ì–´ í€´ì¦ˆ")

                # ì„¸ì…˜ì— ì‚¬ìš©ì ë‹µì•ˆ ì €ì¥
                if "user_answers" not in st.session_state:
                    st.session_state.user_answers = {}

                # ë¬¸ì œ ë Œë”ë§
                for i, q in enumerate(quiz_json["questions"], 1):
                    st.markdown(f"**Q{i}. {q['question']}**")
                    selected = st.radio(
                        label="",
                        options=[f"{j+1}. {opt}" for j, opt in enumerate(q["options"])],
                        key=f"q{i}"
                    )
                    st.session_state.user_answers[i] = selected
            
            # ============================================================
            # Review ëª¨ë“œ
            # ============================================================
            elif st.session_state["mode"] == "review":
                st.markdown("ğŸ“– **ë³µìŠµ ìë£Œ**")
 